{"pageProps": {"talksPageBanner": {"banner": {"title": "TP TEDLive 9/28/23", "slug": "tp-tedlive-9-28-23", "bannerLocation": "talks", "displayToExistingMembers": true, "mainContentHeadline": "Experience the TEDWomen conference from anywhere", "mainContent": "Don't miss out! Be one of the first to see our powerful new talks. ", "buttonLabel": "Count me in", "buttonLink": "https://membership.ted.com/tedwomen-live?utm_medium=website&utm_source=talkpage&utm_campaign=membership-ted&utm_content=09282023-tedlivetp", "showButtonIcon": false, "backgroundColor": "#000000", "textColor": "#FFFFFF", "useBackgroundGradient": false, "imageMobileBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4gxlFyoebOJrZojA12T8oX", "type": "Asset", "createdAt": "2023-09-28T20:19:28.480Z", "updatedAt": "2023-09-28T20:19:28.480Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Portrait Talks (3)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4gxlFyoebOJrZojA12T8oX/bfca75421f299110dacc3d9ed806f94d/TED_Tech_Jun_12_Tablet_Portrait_Talks__3_.png", "details": {"size": 468918, "image": {"width": 1483, "height": 236}}, "fileName": "TED_Tech_Jun_12_Tablet_Portrait_Talks (3).png", "contentType": "image/png"}}}, "imageTabletBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "ObeWsCx1H7GEtlIkKtvyF", "type": "Asset", "createdAt": "2023-09-28T20:19:28.484Z", "updatedAt": "2023-09-28T20:19:28.484Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Landscape Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/ObeWsCx1H7GEtlIkKtvyF/c246b94cd6fadb4394e2b8d2a5c74f0f/TED_Tech_Jun_12_Tablet_Landscape_Talks__5_.png", "details": {"size": 519237, "image": {"width": 2038, "height": 320}}, "fileName": "TED_Tech_Jun_12_Tablet_Landscape_Talks (5).png", "contentType": "image/png"}}}, "imageDesktopBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4mF9JrHls8kG41J85Bg5ZW", "type": "Asset", "createdAt": "2023-09-28T20:19:28.486Z", "updatedAt": "2023-09-28T20:19:28.486Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Desktop Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4mF9JrHls8kG41J85Bg5ZW/621f89a67d4cdc8bb0ddac22065eab6c/TED_Tech_Jun_12_Desktop_Talks__6_.png", "details": {"size": 515590, "image": {"width": 1203, "height": 328}}, "fileName": "TED_Tech_Jun_12_Desktop_Talks (6).png", "contentType": "image/png"}}}, "imageXLBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4OOqb4MoXPyzcuWcMJdjVn", "type": "Asset", "createdAt": "2023-09-28T20:21:34.825Z", "updatedAt": "2023-09-28T20:21:34.825Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Mobile Talks (7)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4OOqb4MoXPyzcuWcMJdjVn/cfa6e256f33e3ed7bd208289f391d750/TED_Tech_Jun_12_Mobile_Talks__7_.png", "details": {"size": 451422, "image": {"width": 1121, "height": 265}}, "fileName": "TED_Tech_Jun_12_Mobile_Talks (7).png", "contentType": "image/png"}}}}, "status": "published"}, "preview": false, "shortenedUrl": "https://go.ted.com/6sWP", "action": null, "videoData": {"__typename": "Video", "id": "2279", "slug": "rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face", "title": "This app knows how you feel -- from the look on your face", "socialTitle": "This app knows how you feel -- from the look on your face", "presenterDisplayName": "Rana el Kaliouby", "internalLanguageCode": "en", "commentsEnabled": false, "commentsLoggedInOnly": false, "recordedOn": "2015-05-28", "curatorApproved": true, "viewedCount": 1786785, "duration": 654, "publishedAt": "2015-06-15T15:46:39Z", "topics": {"__typename": "TopicConnection", "nodes": [{"__typename": "Topic", "id": "10", "name": "technology", "slug": "technology"}, {"__typename": "Topic", "id": "36", "name": "computers", "slug": "computers"}, {"__typename": "Topic", "id": "74", "name": "psychology", "slug": "psychology"}, {"__typename": "Topic", "id": "212", "name": "compassion", "slug": "compassion"}, {"__typename": "Topic", "id": "1161", "name": "emotions", "slug": "emotions"}]}, "talkExtras": {"__typename": "TalkExtras", "recommendations": [{"__typename": "Recommendation", "blurb": "Explore these resources on how emotion is changing technology.", "recLists": [{"__typename": "RecommendationList", "title": "Reading list", "description": "", "recItems": [{"__typename": "RecommendationItem", "blurb": "This book introduces the notion of computers that have the ability to recognize, understand and express emotions. It coined the term \u201caffective computing\u201d and is what inspired me and many others around the world to get into the space of emotion-aware computers.", "eyebrow": null, "headline": "Affective Computing", "isPdf": false, "label": "READ_BOOK", "linkUrl": "http://www.amazon.com/Affective-Computing-Rosalind-W-Picard/dp/0262161702/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Rosalind W. Picard\r\nThe MIT Press, 1997"}, {"__typename": "RecommendationItem", "blurb": "This is a great overview of the history of affective computing and its current applications in business and future directions.", "eyebrow": null, "headline": "We Know How You Feel", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "http://www.newyorker.com/magazine/2015/01/19/know-feel", "note": "Raffi Khatchadourian\r\n*The New Yorker*, January 19, 2015"}, {"__typename": "RecommendationItem", "blurb": "This is a seminal work.", "eyebrow": null, "headline": "The Expression of the Emotions in Man and Animals", "isPdf": false, "label": "READ_BOOK", "linkUrl": "http://www.amazon.com/Expression-Emotions-Man-Animals/dp/1470188880/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Charles Darwin\r\nCreateSpace Independent Publishing Platform, 2012"}, {"__typename": "RecommendationItem", "blurb": "This is an essential reference for all those working in the area of facial analysis and expression. This was the first book I read on facial expressions and is one in a series of Paul Ekman\u2019s groundbreaking works that have been foundational to a lot of what we do today.", "eyebrow": null, "headline": "What the Face Reveals", "isPdf": false, "label": "READ_BOOK", "linkUrl": "http://www.amazon.com/What-Face-Reveals-Spontaneous-Expression/dp/0195179641/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Paul Ekman and Erika L. Rosenberg\r\nOxford University Press, 2005"}, {"__typename": "RecommendationItem", "blurb": "This is a must-read on how we mind-read, effortlessly, automatically and mostly unconsciously, all the time. Simon explains how individuals on the autism spectrum are \u201cmind blind; his work and book inspired my research for building emotion-sensing wearable glasses that help individuals on the autism spectrum read and respond to emotions.", "eyebrow": null, "headline": "Mindblindness", "isPdf": false, "label": "READ_BOOK", "linkUrl": "http://www.amazon.com/Mindblindness-Essay-Autism-Theory-Mind/dp/026252225X/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Simon Baron-Cohen\r\nA Bradford Book, 1997"}, {"__typename": "RecommendationItem", "blurb": "This book argues that emotions are not a luxury \u2014 they are essential to rational thinking and to successful social interactions both in our personal and professional lives. It is a must-read for background and seminal research on why emotions matter.", "eyebrow": null, "headline": "Descartes' Error: Emotion, Reason, and the Human Brain", "isPdf": false, "label": "READ_BOOK", "linkUrl": "http://www.amazon.com/Descartes-Error-Emotion-Reason-Human/dp/014303622X/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Anthony Damasio\r\nPenguin Books, 2005"}]}, {"__typename": "RecommendationList", "title": "Film and video", "description": "", "recItems": [{"__typename": "RecommendationItem", "blurb": "This talk lays a vision for personal robots and how they will transform the way we learn, work and play. Cynthia and I first met at MIT Media Lab. I have always admired her work in social robotics and am a big fan of what she's doing at Jibo today. There is also a lot of synergies between our work \u2014 social robots need to have emotion-sensing capabilities to effectively build rapport with a human owner!", "eyebrow": null, "headline": "Cynthia Breazeal: The rise of personal robots", "isPdf": false, "label": "WATCH", "linkUrl": "http://www.ted.com/talks/cynthia_breazeal_the_rise_of_personal_robots?language=en", "note": "TEDWomen 2010"}, {"__typename": "RecommendationItem", "blurb": "This film takes the idea of an emotionally intelligent device to the extreme! What I find fascinating is how, because this operating system is emotionally intelligent, it persuades its user to do all sorts of things. ", "eyebrow": null, "headline": "Her", "isPdf": false, "label": "EXPLORE", "linkUrl": "http://www.herthemovie.com/#/home", "note": "Warner Bros., 2013"}]}]}], "takeAction": [{"__typename": "TakeActionModule", "blurb": "**Integrate** emotion analytics into your own app.", "endAt": null, "eyebrow": null, "linkUrl": "http://www.affectiva.com/solutions/apis-sdks/", "published": true, "startAt": null, "status": "APPROVED", "verb": "connect", "visibleUrl": "affectiva.com/sdk"}], "learnModules": []}, "primaryImageSet": [{"__typename": "PhotoSize", "url": "https://pe.tedcdn.com/images/ted/d31c54a3a7c3a9d63a6a57407e690ab1a52aad91_2400x1800.jpg", "aspectRatioName": "4x3"}, {"__typename": "PhotoSize", "url": "https://pe.tedcdn.com/images/ted/7942398dd4f5b61691f12872b6e787cf53dec95f_2880x1620.jpg", "aspectRatioName": "16x9"}], "relatedVideos": [{"__typename": "Video", "slug": "david_eagleman_can_we_create_new_senses_for_humans", "id": "2215"}, {"__typename": "Video", "slug": "fei_fei_li_how_we_re_teaching_computers_to_understand_pictures", "id": "2218"}, {"__typename": "Video", "slug": "sherry_turkle_connected_but_alone", "id": "1409"}, {"__typename": "Video", "slug": "tiffany_watt_smith_the_history_of_human_emotions", "id": "7592"}, {"__typename": "Video", "slug": "susan_david_the_gift_and_power_of_emotional_courage", "id": "9463"}, {"__typename": "Video", "slug": "lisa_feldman_barrett_you_aren_t_at_the_mercy_of_your_emotions_your_brain_creates_them", "id": "8419"}], "customContentDetails": {"__typename": "CustomContentDetails", "partnerName": null}, "speakers": {"__typename": "AcmeSpeakerConnection", "nodes": [{"__typename": "AcmeSpeaker", "photoUrl": "https://pe.tedcdn.com/images/ted/de414b319b867763b0479f0502b5584519cd8a77_254x191.jpg", "firstname": "Rana", "middlename": "", "lastname": "el Kaliouby", "description": "Computer scientist", "isLive": true, "title": "", "whatOthersSay": "Kaliouby has a Ph.D. in computer science, and, like many accomplished coders, she has no trouble with mathematical concepts like Bayesian probability and hidden Markov models. But she is also at ease among people: emotive, warm.", "whoTheyAre": "What if a computer could recognize your facial expression, and react to how you feel? Rana el Kaliouby sees big possibilities in making technology emotionally aware.", "whyListen": "<p>Rana el Kaliouby, chief science officer and co-founder of&nbsp;<a href=\"http://www.affectiva.com/\" target=\"_blank\">Affectiva</a>, an MIT Media Lab spin-off, is&nbsp;on a mission to bring emotion intelligence to our digital experiences. She&nbsp;leads the company&#39;s emotion analytics team, which is responsible for developing emotion-sensing algorithms and&nbsp;mining the world&#39;s largest emotion data database. So far, they&#39;ve collected 12 billion emotion data points from 2.9 million face videos from volunteers in 75 countries. The company&rsquo;s platform is used by many Fortune Global 100 companies to measure consumer engagement,&nbsp;and is pioneering emotion-enabled digital apps for enterprise, entertainment, video communication and online education.</p><p><em>Entrepreneur</em> magazine called el Kaliouby one of &ldquo;The 7 Most Powerful Women To Watch in 2014,&rdquo; and the <em>MIT Technology Review</em> included her in their list of the &ldquo;Top 35 Innovators Under 35.&rdquo;</p>", "slug": "rana_el_kaliouby"}]}, "description": "Our emotions influence every aspect of our lives -- how we learn, how we communicate, how we make decisions. Yet they're absent from our digital lives; the devices and apps we interact with have no way of knowing how we feel. Scientist\u00a0Rana el Kaliouby\u00a0aims to change that. She demos a powerful new technology that reads your facial expressions and matches them to corresponding emotions.\u00a0This\u00a0\"emotion engine\"\u00a0has big implications, she says, and could change not just how we interact with machines -- but with each other.", "socialDescription": "Our emotions influence every aspect of our lives -- how we learn, how we communicate, how we make decisions. Yet they're absent from our digital lives; the devices and apps we interact with have no way of knowing how we feel. Scientist\u00a0Rana el Kaliouby\u00a0aims to change that. She demos a powerful new technology that reads your facial expressions and matches them to corresponding emotions.\u00a0This\u00a0\"emotion engine\"\u00a0has big implications, she says, and could change not just how we interact with machines -- but with each other.", "partnerName": null, "playerData": "{\"id\":\"2279\",\"mediaIdentifier\":\"consus-pm3885-im2346\",\"mediaProjectVersionIdentifier\":\"consus-pm3885-im2346\",\"duration\":664,\"languages\":[{\"languageName\":\"Greek\",\"endonym\":\"\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac\",\"languageCode\":\"el\",\"ianaCode\":\"el\",\"isRtl\":false},{\"languageName\":\"English\",\"endonym\":\"English\",\"languageCode\":\"en\",\"ianaCode\":\"en\",\"isRtl\":false},{\"languageName\":\"Vietnamese\",\"endonym\":\"Ti\u1ebfng Vi\u1ec7t\",\"languageCode\":\"vi\",\"ianaCode\":\"vi\",\"isRtl\":false},{\"languageName\":\"Italian\",\"endonym\":\"Italiano\",\"languageCode\":\"it\",\"ianaCode\":\"it\",\"isRtl\":false},{\"languageName\":\"Arabic\",\"endonym\":\"\u0627\u0644\u0639\u0631\u0628\u064a\u0629\",\"languageCode\":\"ar\",\"ianaCode\":\"ar\",\"isRtl\":true},{\"languageName\":\"Portuguese, Brazilian\",\"endonym\":\"Portugu\u00eas brasileiro\",\"languageCode\":\"pt-br\",\"ianaCode\":\"pt-BR\",\"isRtl\":false},{\"languageName\":\"Spanish\",\"endonym\":\"Espa\u00f1ol\",\"languageCode\":\"es\",\"ianaCode\":\"es\",\"isRtl\":false},{\"languageName\":\"Russian\",\"endonym\":\"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\",\"languageCode\":\"ru\",\"ianaCode\":\"ru\",\"isRtl\":false},{\"languageName\":\"Dutch\",\"endonym\":\"Nederlands\",\"languageCode\":\"nl\",\"ianaCode\":\"nl\",\"isRtl\":false},{\"languageName\":\"Portuguese\",\"endonym\":\"Portugu\u00eas de Portugal\",\"languageCode\":\"pt\",\"ianaCode\":\"pt\",\"isRtl\":false},{\"languageName\":\"Chinese, Traditional\",\"endonym\":\"\u4e2d\u6587 (\u7e41\u9ad4)\",\"languageCode\":\"zh-tw\",\"ianaCode\":\"zh-Hant\",\"isRtl\":false},{\"languageName\":\"Turkish\",\"endonym\":\"T\u00fcrk\u00e7e\",\"languageCode\":\"tr\",\"ianaCode\":\"tr\",\"isRtl\":false},{\"languageName\":\"Chinese, Simplified\",\"endonym\":\"\u4e2d\u6587 (\u7b80\u4f53)\",\"languageCode\":\"zh-cn\",\"ianaCode\":\"zh-Hans\",\"isRtl\":false},{\"languageName\":\"Thai\",\"endonym\":\"\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22\",\"languageCode\":\"th\",\"ianaCode\":\"th\",\"isRtl\":false},{\"languageName\":\"Romanian\",\"endonym\":\"Rom\u00e2n\u0103\",\"languageCode\":\"ro\",\"ianaCode\":\"ro\",\"isRtl\":false},{\"languageName\":\"French\",\"endonym\":\"Fran\u00e7ais\",\"languageCode\":\"fr\",\"ianaCode\":\"fr\",\"isRtl\":false},{\"languageName\":\"Croatian\",\"endonym\":\"Hrvatski\",\"languageCode\":\"hr\",\"ianaCode\":\"hr\",\"isRtl\":false},{\"languageName\":\"Persian\",\"endonym\":\"\u0641\u0627\u0631\u0633\u0649\",\"languageCode\":\"fa\",\"ianaCode\":\"fa\",\"isRtl\":true},{\"languageName\":\"Japanese\",\"endonym\":\"\u65e5\u672c\u8a9e\",\"languageCode\":\"ja\",\"ianaCode\":\"ja\",\"isRtl\":false},{\"languageName\":\"Hebrew\",\"endonym\":\"\u05e2\u05d1\u05e8\u05d9\u05ea\",\"languageCode\":\"he\",\"ianaCode\":\"he\",\"isRtl\":true},{\"languageName\":\"Serbian\",\"endonym\":\"\u0421\u0440\u043f\u0441\u043a\u0438, Srpski\",\"languageCode\":\"sr\",\"ianaCode\":\"sr\",\"isRtl\":false},{\"languageName\":\"Albanian\",\"endonym\":\"Shqip\",\"languageCode\":\"sq\",\"ianaCode\":\"sq\",\"isRtl\":false},{\"languageName\":\"Korean\",\"endonym\":\"\ud55c\uad6d\uc5b4\",\"languageCode\":\"ko\",\"ianaCode\":\"ko\",\"isRtl\":false},{\"languageName\":\"Swedish\",\"endonym\":\"Svenska\",\"languageCode\":\"sv\",\"ianaCode\":\"sv\",\"isRtl\":false},{\"languageName\":\"Ukrainian\",\"endonym\":\"\u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\",\"languageCode\":\"uk\",\"ianaCode\":\"uk\",\"isRtl\":false},{\"languageName\":\"Burmese\",\"endonym\":\"\u1019\u103c\u1014\u103a\u1019\u102c\u1018\u102c\u101e\u102c\",\"languageCode\":\"my\",\"ianaCode\":\"my\",\"isRtl\":false},{\"languageName\":\"Hungarian\",\"endonym\":\"Magyar\",\"languageCode\":\"hu\",\"ianaCode\":\"hu\",\"isRtl\":false},{\"languageName\":\"Northern Kurdish (Kurmanji)\",\"endonym\":\"\u06a9\u0648\u0631\u0645\u0627\u0646\u062c\u06cc\",\"languageCode\":\"kmr\",\"ianaCode\":\"ku-kmr\",\"isRtl\":false}],\"nativeLanguage\":\"en\",\"isSubtitleRequired\":false,\"resources\":{\"h264\":[{\"bitrate\":1200,\"file\":\"https://py.tedcdn.com/consus/projects/00/02/67/007/products/2015-rana-el-kaliouby-007-fallback-98fcdf4c66a3599cf1805419f66b4d3a-1200k.mp4\"}],\"hls\":{\"adUrl\":\"https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTEDWomen%2B2015%26id%3D2279%26tag%3Dcompassion%2Ccomputers%2Cpsychology%2Ctechnology%2Cemotions%26talk%3Drana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face%26year%3D2015&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D\",\"maiTargeting\":{\"id\":\"2279\",\"talk\":\"rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face\",\"tag\":\"compassion,computers,psychology,technology,emotions\",\"year\":\"2015\",\"event\":\"TEDWomen 2015\"},\"stream\":\"https://hls.ted.com/project_masters/3885/manifest.m3u8?intro_master_id=2346\",\"metadata\":\"https://hls.ted.com/project_masters/3885/metadata.json?intro_master_id=2346\"}},\"targeting\":{\"id\":\"2279\",\"talk\":\"rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face\",\"tag\":\"compassion,computers,psychology,technology,emotions\",\"year\":\"2015\",\"event\":\"TEDWomen 2015\"},\"canonical\":\"https://www.ted.com/talks/rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face\",\"name\":\"Rana el Kaliouby: This app knows how you feel -- from the look on your face\",\"title\":\"This app knows how you feel -- from the look on your face\",\"speaker\":\"Rana el Kaliouby\",\"thumb\":\"https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/7942398dd4f5b61691f12872b6e787cf53dec95f_2880x1620.jpg?quality=89&w=600\",\"slug\":\"rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face\",\"event\":\"TEDWomen 2015\",\"published\":1434383199,\"external\":{\"service\":\"YouTube\",\"code\":\"o3VwYIazybI\",\"duration\":665.0,\"start_time\":0.0}}", "videoContext": "TEDWomen 2015", "audioInternalLanguageCode": "en", "language": "en", "hasTranslations": true, "featured": true, "type": {"__typename": "TypeOfVideo", "id": "1", "name": "TED Stage Talk"}}, "transcriptData": {"translation": {"__typename": "Translation", "id": "86453", "language": {"__typename": "Language", "id": "35", "endonym": "English", "englishName": "English", "internalLanguageCode": "en", "rtl": false}, "reviewer": null, "translator": null, "paragraphs": [{"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Our emotions influence\nevery aspect of our lives,", "time": 556}, {"__typename": "Cue", "text": "from our health and how we learn,\nto how we do business and make decisions,", "time": 4573}, {"__typename": "Cue", "text": "big ones and small.", "time": 8149}, {"__typename": "Cue", "text": "Our emotions also influence\nhow we connect with one another.", "time": 10672}, {"__typename": "Cue", "text": "We've evolved to live\nin a world like this,", "time": 15132}, {"__typename": "Cue", "text": "but instead, we're living\nmore and more of our lives like this --", "time": 19108}, {"__typename": "Cue", "text": "this is the text message\nfrom my daughter last night --", "time": 23427}, {"__typename": "Cue", "text": "in a world that's devoid of emotion.", "time": 26561}, {"__typename": "Cue", "text": "So I'm on a mission to change that.", "time": 29301}, {"__typename": "Cue", "text": "I want to bring emotions\nback into our digital experiences.", "time": 31252}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I started on this path 15 years ago.", "time": 36223}, {"__typename": "Cue", "text": "I was a computer scientist in Egypt,", "time": 39300}, {"__typename": "Cue", "text": "and I had just gotten accepted to\na Ph.D. program at Cambridge University.", "time": 41366}, {"__typename": "Cue", "text": "So I did something quite unusual", "time": 45871}, {"__typename": "Cue", "text": "for a young newlywed Muslim Egyptian wife:", "time": 47984}, {"__typename": "Cue", "text": "With the support of my husband,\nwho had to stay in Egypt,", "time": 53599}, {"__typename": "Cue", "text": "I packed my bags and I moved to England.", "time": 56598}, {"__typename": "Cue", "text": "At Cambridge, thousands of miles\naway from home,", "time": 59616}, {"__typename": "Cue", "text": "I realized I was spending\nmore hours with my laptop", "time": 62844}, {"__typename": "Cue", "text": "than I did with any other human.", "time": 66257}, {"__typename": "Cue", "text": "Yet despite this intimacy, my laptop\nhad absolutely no idea how I was feeling.", "time": 68486}, {"__typename": "Cue", "text": "It had no idea if I was happy,", "time": 73339}, {"__typename": "Cue", "text": "having a bad day, or stressed, confused,", "time": 76550}, {"__typename": "Cue", "text": "and so that got frustrating.", "time": 79538}, {"__typename": "Cue", "text": "Even worse, as I communicated\nonline with my family back home,", "time": 83600}, {"__typename": "Cue", "text": "I felt that all my emotions\ndisappeared in cyberspace.", "time": 89421}, {"__typename": "Cue", "text": "I was homesick, I was lonely,\nand on some days I was actually crying,", "time": 92703}, {"__typename": "Cue", "text": "but all I had to communicate\nthese emotions was this.", "time": 97858}, {"__typename": "Cue", "text": "(Laughter)", "time": 102786}, {"__typename": "Cue", "text": "Today's technology\nhas lots of I.Q., but no E.Q.;", "time": 104806}, {"__typename": "Cue", "text": "lots of cognitive intelligence,\nbut no emotional intelligence.", "time": 109780}, {"__typename": "Cue", "text": "So that got me thinking,", "time": 112956}, {"__typename": "Cue", "text": "what if our technology\ncould sense our emotions?", "time": 115153}, {"__typename": "Cue", "text": "What if our devices could sense\nhow we felt and reacted accordingly,", "time": 118777}, {"__typename": "Cue", "text": "just the way an emotionally\nintelligent friend would?", "time": 122853}, {"__typename": "Cue", "text": "Those questions led me and my team", "time": 126666}, {"__typename": "Cue", "text": "to create technologies that can read\nand respond to our emotions,", "time": 130230}, {"__typename": "Cue", "text": "and our starting point was the human face.", "time": 134607}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So our human face happens to be\none of the most powerful channels", "time": 138577}, {"__typename": "Cue", "text": "that we all use to communicate\nsocial and emotional states,", "time": 141750}, {"__typename": "Cue", "text": "everything from enjoyment, surprise,", "time": 145766}, {"__typename": "Cue", "text": "empathy and curiosity.", "time": 148776}, {"__typename": "Cue", "text": "In emotion science, we call each\nfacial muscle movement an action unit.", "time": 152979}, {"__typename": "Cue", "text": "So for example, action unit 12,", "time": 157907}, {"__typename": "Cue", "text": "it's not a Hollywood blockbuster,", "time": 160832}, {"__typename": "Cue", "text": "it is actually a lip corner pull,\nwhich is the main component of a smile.", "time": 162870}, {"__typename": "Cue", "text": "Try it everybody. Let's get\nsome smiles going on.", "time": 166312}, {"__typename": "Cue", "text": "Another example is action unit 4.\nIt's the brow furrow.", "time": 169300}, {"__typename": "Cue", "text": "It's when you draw your eyebrows together", "time": 171954}, {"__typename": "Cue", "text": "and you create all\nthese textures and wrinkles.", "time": 174192}, {"__typename": "Cue", "text": "We don't like them, but it's\na strong indicator of a negative emotion.", "time": 176459}, {"__typename": "Cue", "text": "So we have about 45 of these action units,", "time": 180754}, {"__typename": "Cue", "text": "and they combine to express\nhundreds of emotions.", "time": 182960}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Teaching a computer to read\nthese facial emotions is hard,", "time": 186350}, {"__typename": "Cue", "text": "because these action units,\nthey can be fast, they're subtle,", "time": 190251}, {"__typename": "Cue", "text": "and they combine in many different ways.", "time": 193223}, {"__typename": "Cue", "text": "So take, for example,\nthe smile and the smirk.", "time": 195777}, {"__typename": "Cue", "text": "They look somewhat similar,\nbut they mean very different things.", "time": 199515}, {"__typename": "Cue", "text": "(Laughter)", "time": 203268}, {"__typename": "Cue", "text": "So the smile is positive,", "time": 204986}, {"__typename": "Cue", "text": "a smirk is often negative.", "time": 207990}, {"__typename": "Cue", "text": "Sometimes a smirk\ncan make you become famous.", "time": 209260}, {"__typename": "Cue", "text": "But seriously, it's important\nfor a computer to be able", "time": 213136}, {"__typename": "Cue", "text": "to tell the difference\nbetween the two expressions.", "time": 215960}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So how do we do that?", "time": 218815}, {"__typename": "Cue", "text": "We give our algorithms", "time": 220627}, {"__typename": "Cue", "text": "tens of thousands of examples\nof people we know to be smiling,", "time": 222414}, {"__typename": "Cue", "text": "from different ethnicities, ages, genders,", "time": 226524}, {"__typename": "Cue", "text": "and we do the same for smirks.", "time": 229589}, {"__typename": "Cue", "text": "And then, using deep learning,", "time": 232400}, {"__typename": "Cue", "text": "the algorithm looks for all these\ntextures and wrinkles", "time": 233954}, {"__typename": "Cue", "text": "and shape changes on our face,", "time": 236810}, {"__typename": "Cue", "text": "and basically learns that all smiles\nhave common characteristics,", "time": 239390}, {"__typename": "Cue", "text": "all smirks have subtly\ndifferent characteristics.", "time": 242592}, {"__typename": "Cue", "text": "And the next time it sees a new face,", "time": 245773}, {"__typename": "Cue", "text": "it essentially learns that", "time": 248141}, {"__typename": "Cue", "text": "this face has the same\ncharacteristics of a smile,", "time": 250440}, {"__typename": "Cue", "text": "and it says, \"Aha, I recognize this.\nThis is a smile expression.\"", "time": 253473}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So the best way to demonstrate\nhow this technology works", "time": 258381}, {"__typename": "Cue", "text": "is to try a live demo,", "time": 261181}, {"__typename": "Cue", "text": "so I need a volunteer,\npreferably somebody with a face.", "time": 263317}, {"__typename": "Cue", "text": "(Laughter)", "time": 267230}, {"__typename": "Cue", "text": "Cloe's going to be our volunteer today.", "time": 269564}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So over the past five years, we've moved\nfrom being a research project at MIT", "time": 273325}, {"__typename": "Cue", "text": "to a company,", "time": 277783}, {"__typename": "Cue", "text": "where my team has worked really hard\nto make this technology work,", "time": 278939}, {"__typename": "Cue", "text": "as we like to say, in the wild.", "time": 282131}, {"__typename": "Cue", "text": "And we've also shrunk it so that\nthe core emotion engine", "time": 284540}, {"__typename": "Cue", "text": "works on any mobile device\nwith a camera, like this iPad.", "time": 287210}, {"__typename": "Cue", "text": "So let's give this a try.", "time": 290530}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "As you can see, the algorithm\nhas essentially found Cloe's face,", "time": 294756}, {"__typename": "Cue", "text": "so it's this white bounding box,", "time": 298680}, {"__typename": "Cue", "text": "and it's tracking the main\nfeature points on her face,", "time": 300372}, {"__typename": "Cue", "text": "so her eyebrows, her eyes,\nher mouth and her nose.", "time": 302943}, {"__typename": "Cue", "text": "The question is,\ncan it recognize her expression?", "time": 305799}, {"__typename": "Cue", "text": "So we're going to test the machine.", "time": 308786}, {"__typename": "Cue", "text": "So first of all, give me your poker face.\nYep, awesome. (Laughter)", "time": 310457}, {"__typename": "Cue", "text": "And then as she smiles,\nthis is a genuine smile, it's great.", "time": 314643}, {"__typename": "Cue", "text": "So you can see the green bar\ngo up as she smiles.", "time": 317456}, {"__typename": "Cue", "text": "Now that was a big smile.", "time": 319756}, {"__typename": "Cue", "text": "Can you try a subtle smile\nto see if the computer can recognize?", "time": 320978}, {"__typename": "Cue", "text": "It does recognize subtle smiles as well.", "time": 324021}, {"__typename": "Cue", "text": "We've worked really hard\nto make that happen.", "time": 326352}, {"__typename": "Cue", "text": "And then eyebrow raised,\nindicator of surprise.", "time": 328477}, {"__typename": "Cue", "text": "Brow furrow, which is\nan indicator of confusion.", "time": 331439}, {"__typename": "Cue", "text": "Frown. Yes, perfect.", "time": 335688}, {"__typename": "Cue", "text": "So these are all the different\naction units. There's many more of them.", "time": 339695}, {"__typename": "Cue", "text": "This is just a slimmed-down demo.", "time": 343188}, {"__typename": "Cue", "text": "But we call each reading\nan emotion data point,", "time": 345220}, {"__typename": "Cue", "text": "and then they can fire together\nto portray different emotions.", "time": 348368}, {"__typename": "Cue", "text": "So on the right side of the demo --\nlook like you're happy.", "time": 351337}, {"__typename": "Cue", "text": "So that's joy. Joy fires up.", "time": 355990}, {"__typename": "Cue", "text": "And then give me a disgust face.", "time": 357444}, {"__typename": "Cue", "text": "Try to remember what it was like\nwhen Zayn left One Direction.", "time": 359371}, {"__typename": "Cue", "text": "(Laughter)", "time": 363643}, {"__typename": "Cue", "text": "Yeah, wrinkle your nose. Awesome.", "time": 365153}, {"__typename": "Cue", "text": "And the valence is actually quite\nnegative, so you must have been a big fan.", "time": 369495}, {"__typename": "Cue", "text": "So valence is how positive\nor negative an experience is,", "time": 373226}, {"__typename": "Cue", "text": "and engagement is how\nexpressive she is as well.", "time": 375926}, {"__typename": "Cue", "text": "So imagine if Cloe had access\nto this real-time emotion stream,", "time": 378712}, {"__typename": "Cue", "text": "and she could share it\nwith anybody she wanted to.", "time": 382126}, {"__typename": "Cue", "text": "Thank you.", "time": 384935}, {"__typename": "Cue", "text": "(Applause)", "time": 387858}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So, so far, we have amassed\n12 billion of these emotion data points.", "time": 393749}, {"__typename": "Cue", "text": "It's the largest emotion\ndatabase in the world.", "time": 399019}, {"__typename": "Cue", "text": "We've collected it\nfrom 2.9 million face videos,", "time": 401630}, {"__typename": "Cue", "text": "people who have agreed\nto share their emotions with us,", "time": 404593}, {"__typename": "Cue", "text": "and from 75 countries around the world.", "time": 407193}, {"__typename": "Cue", "text": "It's growing every day.", "time": 410398}, {"__typename": "Cue", "text": "It blows my mind away", "time": 412603}, {"__typename": "Cue", "text": "that we can now quantify something\nas personal as our emotions,", "time": 414670}, {"__typename": "Cue", "text": "and we can do it at this scale.", "time": 417865}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So what have we learned to date?", "time": 420100}, {"__typename": "Cue", "text": "Gender.", "time": 423057}, {"__typename": "Cue", "text": "Our data confirms something\nthat you might suspect.", "time": 425388}, {"__typename": "Cue", "text": "Women are more expressive than men.", "time": 429034}, {"__typename": "Cue", "text": "Not only do they smile more,\ntheir smiles last longer,", "time": 430891}, {"__typename": "Cue", "text": "and we can now really quantify\nwhat it is that men and women", "time": 433574}, {"__typename": "Cue", "text": "respond to differently.", "time": 436478}, {"__typename": "Cue", "text": "Let's do culture: So in the United States,", "time": 438614}, {"__typename": "Cue", "text": "women are 40 percent\nmore expressive than men,", "time": 440904}, {"__typename": "Cue", "text": "but curiously, we don't see any difference\nin the U.K. between men and women.", "time": 444108}, {"__typename": "Cue", "text": "(Laughter)", "time": 447753}, {"__typename": "Cue", "text": "Age: People who are 50 years and older", "time": 451296}, {"__typename": "Cue", "text": "are 25 percent more emotive\nthan younger people.", "time": 455323}, {"__typename": "Cue", "text": "Women in their 20s smile a lot more\nthan men the same age,", "time": 459899}, {"__typename": "Cue", "text": "perhaps a necessity for dating.", "time": 463751}, {"__typename": "Cue", "text": "But perhaps what surprised us\nthe most about this data", "time": 467590}, {"__typename": "Cue", "text": "is that we happen\nto be expressive all the time,", "time": 470207}, {"__typename": "Cue", "text": "even when we are sitting\nin front of our devices alone,", "time": 473410}, {"__typename": "Cue", "text": "and it's not just when we're watching\ncat videos on Facebook.", "time": 476243}, {"__typename": "Cue", "text": "We are expressive when we're emailing,\ntexting, shopping online,", "time": 480217}, {"__typename": "Cue", "text": "or even doing our taxes.", "time": 483227}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Where is this data used today?", "time": 485527}, {"__typename": "Cue", "text": "In understanding how we engage with media,", "time": 487919}, {"__typename": "Cue", "text": "so understanding virality\nand voting behavior;", "time": 490682}, {"__typename": "Cue", "text": "and also empowering\nor emotion-enabling technology,", "time": 493166}, {"__typename": "Cue", "text": "and I want to share some examples\nthat are especially close to my heart.", "time": 495906}, {"__typename": "Cue", "text": "Emotion-enabled wearable glasses\ncan help individuals", "time": 501197}, {"__typename": "Cue", "text": "who are visually impaired\nread the faces of others,", "time": 504265}, {"__typename": "Cue", "text": "and it can help individuals\non the autism spectrum interpret emotion,", "time": 507493}, {"__typename": "Cue", "text": "something that they really struggle with.", "time": 511680}, {"__typename": "Cue", "text": "In education, imagine\nif your learning apps", "time": 515918}, {"__typename": "Cue", "text": "sense that you're confused and slow down,", "time": 518777}, {"__typename": "Cue", "text": "or that you're bored, so it's sped up,", "time": 521587}, {"__typename": "Cue", "text": "just like a great teacher\nwould in a classroom.", "time": 523444}, {"__typename": "Cue", "text": "What if your wristwatch tracked your mood,", "time": 527043}, {"__typename": "Cue", "text": "or your car sensed that you're tired,", "time": 529644}, {"__typename": "Cue", "text": "or perhaps your fridge\nknows that you're stressed,", "time": 532337}, {"__typename": "Cue", "text": "so it auto-locks to prevent you\nfrom binge eating. (Laughter)", "time": 534885}, {"__typename": "Cue", "text": "I would like that, yeah.", "time": 540951}, {"__typename": "Cue", "text": "What if, when I was in Cambridge,", "time": 543668}, {"__typename": "Cue", "text": "I had access to my real-time\nemotion stream,", "time": 545595}, {"__typename": "Cue", "text": "and I could share that with my family\nback home in a very natural way,", "time": 547908}, {"__typename": "Cue", "text": "just like I would've if we were all\nin the same room together?", "time": 551437}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I think five years down the line,", "time": 555408}, {"__typename": "Cue", "text": "all our devices are going\nto have an emotion chip,", "time": 558550}, {"__typename": "Cue", "text": "and we won't remember what it was like\nwhen we couldn't just frown at our device", "time": 560887}, {"__typename": "Cue", "text": "and our device would say, \"Hmm,\nyou didn't like that, did you?\"", "time": 564951}, {"__typename": "Cue", "text": "Our biggest challenge is that there are\nso many applications of this technology,", "time": 569200}, {"__typename": "Cue", "text": "my team and I realize that we can't\nbuild them all ourselves,", "time": 572961}, {"__typename": "Cue", "text": "so we've made this technology available\nso that other developers", "time": 575864}, {"__typename": "Cue", "text": "can get building and get creative.", "time": 579360}, {"__typename": "Cue", "text": "We recognize that\nthere are potential risks", "time": 581474}, {"__typename": "Cue", "text": "and potential for abuse,", "time": 585560}, {"__typename": "Cue", "text": "but personally, having spent\nmany years doing this,", "time": 587627}, {"__typename": "Cue", "text": "I believe that the benefits to humanity", "time": 590576}, {"__typename": "Cue", "text": "from having emotionally\nintelligent technology", "time": 593548}, {"__typename": "Cue", "text": "far outweigh the potential for misuse.", "time": 595823}, {"__typename": "Cue", "text": "And I invite you all to be\npart of the conversation.", "time": 599399}, {"__typename": "Cue", "text": "The more people who know\nabout this technology,", "time": 601930}, {"__typename": "Cue", "text": "the more we can all have a voice\nin how it's being used.", "time": 604484}, {"__typename": "Cue", "text": "So as more and more\nof our lives become digital,", "time": 609081}, {"__typename": "Cue", "text": "we are fighting a losing battle\ntrying to curb our usage of devices", "time": 613655}, {"__typename": "Cue", "text": "in order to reclaim our emotions.", "time": 617153}, {"__typename": "Cue", "text": "So what I'm trying to do instead\nis to bring emotions into our technology", "time": 620622}, {"__typename": "Cue", "text": "and make our technologies more responsive.", "time": 624536}, {"__typename": "Cue", "text": "So I want those devices\nthat have separated us", "time": 626765}, {"__typename": "Cue", "text": "to bring us back together.", "time": 629435}, {"__typename": "Cue", "text": "And by humanizing technology,\nwe have this golden opportunity", "time": 631897}, {"__typename": "Cue", "text": "to reimagine how we\nconnect with machines,", "time": 636485}, {"__typename": "Cue", "text": "and therefore, how we, as human beings,", "time": 639782}, {"__typename": "Cue", "text": "connect with one another.", "time": 644263}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Thank you.", "time": 646167}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Applause)", "time": 648327}]}]}, "video": {"__typename": "Video", "id": "2279", "talkExtras": {"__typename": "TalkExtras", "footnotes": [{"__typename": "Footnote", "author": null, "annotation": "In 2009, Professor Rosalind Picard and I spun out of MIT Media Lab and co-founded [Affectiva] (http://www.affectiva.com).\r\nToday, Affectiva develops software that maps people's facial expressions into emotions unobtrusively and at scale ", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "04:46", "title": null, "category": "note"}]}}}, "commentsEnabled": false, "commentsLoggedInOnly": false}, "language": "en", "messages": {}, "responseCode": 200, "__N_SSP": true}