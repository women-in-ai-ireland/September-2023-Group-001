{"pageProps": {"talksPageBanner": {"banner": {"title": "TP TEDLive 9/28/23", "slug": "tp-tedlive-9-28-23", "bannerLocation": "talks", "displayToExistingMembers": true, "mainContentHeadline": "Experience the TEDWomen conference from anywhere", "mainContent": "Don't miss out! Be one of the first to see our powerful new talks. ", "buttonLabel": "Count me in", "buttonLink": "https://membership.ted.com/tedwomen-live?utm_medium=website&utm_source=talkpage&utm_campaign=membership-ted&utm_content=09282023-tedlivetp", "showButtonIcon": false, "backgroundColor": "#000000", "textColor": "#FFFFFF", "useBackgroundGradient": false, "imageMobileBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4gxlFyoebOJrZojA12T8oX", "type": "Asset", "createdAt": "2023-09-28T20:19:28.480Z", "updatedAt": "2023-09-28T20:19:28.480Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Portrait Talks (3)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4gxlFyoebOJrZojA12T8oX/bfca75421f299110dacc3d9ed806f94d/TED_Tech_Jun_12_Tablet_Portrait_Talks__3_.png", "details": {"size": 468918, "image": {"width": 1483, "height": 236}}, "fileName": "TED_Tech_Jun_12_Tablet_Portrait_Talks (3).png", "contentType": "image/png"}}}, "imageTabletBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "ObeWsCx1H7GEtlIkKtvyF", "type": "Asset", "createdAt": "2023-09-28T20:19:28.484Z", "updatedAt": "2023-09-28T20:19:28.484Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Landscape Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/ObeWsCx1H7GEtlIkKtvyF/c246b94cd6fadb4394e2b8d2a5c74f0f/TED_Tech_Jun_12_Tablet_Landscape_Talks__5_.png", "details": {"size": 519237, "image": {"width": 2038, "height": 320}}, "fileName": "TED_Tech_Jun_12_Tablet_Landscape_Talks (5).png", "contentType": "image/png"}}}, "imageDesktopBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4mF9JrHls8kG41J85Bg5ZW", "type": "Asset", "createdAt": "2023-09-28T20:19:28.486Z", "updatedAt": "2023-09-28T20:19:28.486Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Desktop Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4mF9JrHls8kG41J85Bg5ZW/621f89a67d4cdc8bb0ddac22065eab6c/TED_Tech_Jun_12_Desktop_Talks__6_.png", "details": {"size": 515590, "image": {"width": 1203, "height": 328}}, "fileName": "TED_Tech_Jun_12_Desktop_Talks (6).png", "contentType": "image/png"}}}, "imageXLBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4OOqb4MoXPyzcuWcMJdjVn", "type": "Asset", "createdAt": "2023-09-28T20:21:34.825Z", "updatedAt": "2023-09-28T20:21:34.825Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Mobile Talks (7)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4OOqb4MoXPyzcuWcMJdjVn/cfa6e256f33e3ed7bd208289f391d750/TED_Tech_Jun_12_Mobile_Talks__7_.png", "details": {"size": 451422, "image": {"width": 1121, "height": 265}}, "fileName": "TED_Tech_Jun_12_Mobile_Talks (7).png", "contentType": "image/png"}}}}, "status": "published"}, "preview": false, "shortenedUrl": "https://go.ted.com/6Wna", "action": null, "videoData": {"__typename": "Video", "id": "114533", "slug": "eliezer_yudkowsky_will_superintelligent_ai_end_the_world", "title": "Will superintelligent AI end the world?", "socialTitle": "Will superintelligent AI end the world?", "presenterDisplayName": "Eliezer Yudkowsky", "internalLanguageCode": "en", "commentsEnabled": true, "commentsLoggedInOnly": true, "recordedOn": "2023-04-18", "curatorApproved": true, "viewedCount": 1063897, "duration": 632, "publishedAt": "2023-07-11T14:40:19Z", "topics": {"__typename": "TopicConnection", "nodes": [{"__typename": "Topic", "id": "8", "name": "science", "slug": "science"}, {"__typename": "Topic", "id": "10", "name": "technology", "slug": "technology"}, {"__typename": "Topic", "id": "80", "name": "future", "slug": "future"}, {"__typename": "Topic", "id": "184", "name": "AI", "slug": "ai"}, {"__typename": "Topic", "id": "478", "name": "machine learning", "slug": "machine+learning"}]}, "talkExtras": {"__typename": "TalkExtras", "recommendations": [{"__typename": "Recommendation", "blurb": "", "recLists": [{"__typename": "RecommendationList", "title": "", "description": "", "recItems": [{"__typename": "RecommendationItem", "blurb": "A recent *New York Times* article reports that the world's top three artificial intelligence labs (Google DeepMind, OpenAI and Anthropic) are acutely worried about future artificial intelligence advances causing human extinction. These worries are echoed by two of the godfathers of modern machine learning: Geoffrey Hinton and Yoshua Bengio.", "eyebrow": "", "headline": "\"A.I. Poses 'Risk of Extinction,' Industry Leaders Warn\"", "isPdf": false, "label": "READ_BOOK", "linkUrl": "https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html", "note": "Kevin Roose\r\n*New York Times*, 2023"}, {"__typename": "RecommendationItem", "blurb": "A *Financial Times* article goes into more detail on the shape of the worry: increasingly general and capable systems with unpredictable capabilities and behavior, and the growing possibility that we\u2019ll soon see \u201cgod-like\u201d smarter-than-human systems.", "eyebrow": "", "headline": "\"We must slow down the race to god-like AI\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2", "note": "Ian Hogarth\r\n*Financial Times*, 2023"}, {"__typename": "RecommendationItem", "blurb": "A short essay by Yudkowsky arguing for an international treaty prohibiting large AI training runs until the field knows how to make smarter-than-human AI safe\u2014something that Yudkowsky expects to take many decades and a number of major conceptual breakthroughs.", "eyebrow": "", "headline": "\"Pausing AI Developments Isn't Enough. We Need to Shut it All Down\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/", "note": "Eliezer Yudkowsky\r\n*TIME*, 2023"}, {"__typename": "RecommendationItem", "blurb": "A longer essay by Yudkowsky, aimed primarily at industry insiders, describing the many specific obstacles to getting good behavior from powerful AI systems.", "eyebrow": "", "headline": "\"AGI Ruin: A List of Lethalities\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "https://www.alignmentforum.org/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities", "note": "Eliezer Yudkowsky\r\nAI Alignment Forum, 2022"}, {"__typename": "RecommendationItem", "blurb": "Explore the website of the Machine Intelligence Research Institute.", "eyebrow": "", "headline": "Machine Intelligence Research Institute", "isPdf": false, "label": "EXPLORE", "linkUrl": "https://intelligence.org/", "note": "intelligence.org"}]}]}], "takeAction": [{"__typename": "TakeActionModule", "blurb": "Learn more about smarter-than-human artificial intelligence.", "endAt": null, "eyebrow": null, "linkUrl": "https://intelligence.org/", "published": true, "startAt": null, "status": "APPROVED", "verb": "learn", "visibleUrl": "intelligence.org"}], "learnModules": []}, "primaryImageSet": [{"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/cffc3713-eca7-4c10-95a7-8cc563e50de9/EliezerYudkowsky_2023-embed.jpg", "aspectRatioName": "16x9"}, {"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/6269150e-bb8f-444a-8b7d-0debd0475c59/EliezerYudkowsky_2023-stageshot.jpg", "aspectRatioName": "4x3"}, {"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/01c4a743-3c91-4ca9-abc3-2dd8566c4821/EliezerYudkowsky_2023-1350x675.jpg", "aspectRatioName": "2x1"}], "relatedVideos": [{"__typename": "Video", "slug": "alexandr_wang_war_ai_and_the_new_global_arms_race", "id": "113936"}, {"__typename": "Video", "slug": "yejin_choi_why_ai_is_incredibly_smart_and_shockingly_stupid", "id": "110502"}, {"__typename": "Video", "slug": "nita_farahany_your_right_to_mental_privacy_in_the_age_of_brain_sensing_tech", "id": "111748"}, {"__typename": "Video", "slug": "tom_gruber_how_ai_can_enhance_our_memory_work_and_social_lives", "id": "2841"}, {"__typename": "Video", "slug": "max_tegmark_how_to_get_empowered_not_overpowered_by_ai", "id": "17851"}, {"__typename": "Video", "slug": "kevin_kelly_how_ai_can_bring_on_a_second_industrial_revolution", "id": "2645"}], "customContentDetails": {"__typename": "CustomContentDetails", "partnerName": null}, "speakers": {"__typename": "AcmeSpeakerConnection", "nodes": [{"__typename": "AcmeSpeaker", "photoUrl": "https://ted-conferences-speaker-photos-production.s3.amazonaws.com/0g751cv3zcdsepxzfgzv1w7wlkd4", "firstname": "Eliezer", "middlename": "", "lastname": "Yudkowsky", "description": "Decision theorist", "isLive": true, "title": "", "whatOthersSay": "", "whoTheyAre": "Eliezer Yudkowsky is a foundational thinker on the long-term future of artificial intelligence.", "whyListen": "<div>With more than 20 years of experience in the world of artificial intelligence, Eliezer Yudkowsky is a founder and research fellow at the Machine Intelligence Research Institute, a nonprofit established to ensure that smarter-than-human AI has a positive impact on the world.<br><br>For decades, Yudkowsky has warned about the problem of \"unfriendly\" or \"misaligned\" smarter-than-human AI, and has pushed for technical research on making AI systems more reliable and predictable. Those worries have since gone mainstream, as industry leaders have come together to issue a public warning that \"human extinction\" is a genuine risk of future breakthroughs in AI. Yudkowsky's call to action is a simple one: we need an immediate, indefinite, worldwide moratorium on developing generalist frontier artificial intelligence systems.</div>", "slug": "eliezer_yudkowsky"}]}, "description": "Decision theorist Eliezer Yudkowsky has a simple message: superintelligent AI could probably kill us all. So the question becomes: Is it possible to build powerful artificial minds that are obedient, even benevolent? In a fiery talk, Yudkowsky explores why we need to act immediately to ensure smarter-than-human AI systems don't lead to our extinction.", "socialDescription": "Decision theorist Eliezer Yudkowsky has a simple message: superintelligent AI could probably kill us all. So the question becomes: Is it possible to build powerful artificial minds that are obedient, even benevolent? In a fiery talk, Yudkowsky explores why we need to act immediately to ensure smarter-than-human AI systems don't lead to our extinction.", "partnerName": null, "playerData": "{\"id\":\"114533\",\"mediaIdentifier\":\"consus-pm8581-im2346\",\"mediaProjectVersionIdentifier\":\"consus-pm8581-im2346\",\"duration\":629,\"languages\":[{\"languageName\":\"English\",\"endonym\":\"English\",\"languageCode\":\"en\",\"ianaCode\":\"en\",\"isRtl\":false},{\"languageName\":\"Vietnamese\",\"endonym\":\"Ti\u1ebfng Vi\u1ec7t\",\"languageCode\":\"vi\",\"ianaCode\":\"vi\",\"isRtl\":false},{\"languageName\":\"Chinese, Simplified\",\"endonym\":\"\u4e2d\u6587 (\u7b80\u4f53)\",\"languageCode\":\"zh-cn\",\"ianaCode\":\"zh-Hans\",\"isRtl\":false},{\"languageName\":\"French\",\"endonym\":\"Fran\u00e7ais\",\"languageCode\":\"fr\",\"ianaCode\":\"fr\",\"isRtl\":false},{\"languageName\":\"Korean\",\"endonym\":\"\ud55c\uad6d\uc5b4\",\"languageCode\":\"ko\",\"ianaCode\":\"ko\",\"isRtl\":false},{\"languageName\":\"Persian\",\"endonym\":\"\u0641\u0627\u0631\u0633\u0649\",\"languageCode\":\"fa\",\"ianaCode\":\"fa\",\"isRtl\":true},{\"languageName\":\"Spanish\",\"endonym\":\"Espa\u00f1ol\",\"languageCode\":\"es\",\"ianaCode\":\"es\",\"isRtl\":false},{\"languageName\":\"Russian\",\"endonym\":\"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\",\"languageCode\":\"ru\",\"ianaCode\":\"ru\",\"isRtl\":false}],\"nativeLanguage\":\"en\",\"isSubtitleRequired\":false,\"resources\":{\"h264\":[{\"bitrate\":1200,\"file\":\"https://py.tedcdn.com/consus/projects/00/65/75/001/products/2023-eliezer-yudkowsky-001-fallback-abb13836-cd3d-4c17-9051-07f0b1f585ff-1200k.mp4\"}],\"hls\":{\"adUrl\":\"https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTED2023%26id%3D114533%26tag%3DAI%2Ctechnology%2Cscience%2Cmachine%2Blearning%2Cfuture%26talk%3Deliezer_yudkowsky_will_superintelligent_ai_end_the_world%26year%3D2023&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D\",\"maiTargeting\":{\"id\":\"114533\",\"talk\":\"eliezer_yudkowsky_will_superintelligent_ai_end_the_world\",\"tag\":\"AI,technology,science,machine learning,future\",\"year\":\"2023\",\"event\":\"TED2023\"},\"stream\":\"https://hls.ted.com/project_masters/8581/manifest.m3u8?intro_master_id=2346\",\"metadata\":\"https://hls.ted.com/project_masters/8581/metadata.json?intro_master_id=2346\"}},\"targeting\":{\"id\":\"114533\",\"talk\":\"eliezer_yudkowsky_will_superintelligent_ai_end_the_world\",\"tag\":\"AI,technology,science,machine learning,future\",\"year\":\"2023\",\"event\":\"TED2023\"},\"canonical\":\"https://www.ted.com/talks/eliezer_yudkowsky_will_superintelligent_ai_end_the_world\",\"name\":\"Eliezer Yudkowsky: Will superintelligent AI end the world?\",\"title\":\"Will superintelligent AI end the world?\",\"speaker\":\"Eliezer Yudkowsky\",\"thumb\":\"https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/cffc3713-eca7-4c10-95a7-8cc563e50de9/EliezerYudkowsky_2023-embed.jpg?quality=89&w=600\",\"slug\":\"eliezer_yudkowsky_will_superintelligent_ai_end_the_world\",\"event\":\"TED2023\",\"published\":1689086419,\"external\":{\"service\":\"YouTube\",\"code\":\"Yd0yQ9yxSYY\",\"duration\":0.0,\"start_time\":0.0}}", "videoContext": "TED2023", "audioInternalLanguageCode": "en", "language": "en", "hasTranslations": true, "featured": true, "type": {"__typename": "TypeOfVideo", "id": "1", "name": "TED Stage Talk"}}, "transcriptData": {"translation": {"__typename": "Translation", "id": "231162", "language": {"__typename": "Language", "id": "35", "endonym": "English", "englishName": "English", "internalLanguageCode": "en", "rtl": false}, "reviewer": null, "translator": null, "paragraphs": [{"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Since 2001, I have been working\non what we would now call", "time": 830}, {"__typename": "Cue", "text": "the problem of aligning artificial\ngeneral intelligence:", "time": 4375}, {"__typename": "Cue", "text": "how to shape the preferences and behavior", "time": 8046}, {"__typename": "Cue", "text": "of a powerful artificial mind\nsuch that it does not kill everyone.", "time": 10173}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I more or less founded the field\ntwo decades ago,", "time": 15720}, {"__typename": "Cue", "text": "when nobody else considered it\nrewarding enough to work on.", "time": 18848}, {"__typename": "Cue", "text": "I tried to get this very important\nproject started early", "time": 21642}, {"__typename": "Cue", "text": "so we'd be in less\nof a drastic rush later.", "time": 24395}, {"__typename": "Cue", "text": "I consider myself to have failed.", "time": 27565}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 29650}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Nobody understands how modern\nAI systems do what they do.", "time": 30693}, {"__typename": "Cue", "text": "They are giant, inscrutable matrices\nof floating point numbers", "time": 34072}, {"__typename": "Cue", "text": "that we nudge in the direction\nof better performance", "time": 37075}, {"__typename": "Cue", "text": "until they inexplicably start working.", "time": 39535}, {"__typename": "Cue", "text": "At some point, the companies\nrushing headlong to scale AI", "time": 41579}, {"__typename": "Cue", "text": "will cough out something\nthat's smarter than humanity.", "time": 44957}, {"__typename": "Cue", "text": "Nobody knows how to calculate\nwhen that will happen.", "time": 47627}, {"__typename": "Cue", "text": "My wild guess is that it will happen\nafter zero to two more breakthroughs", "time": 50171}, {"__typename": "Cue", "text": "the size of transformers.", "time": 53925}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "What happens if we build\nsomething smarter than us", "time": 55635}, {"__typename": "Cue", "text": "that we understand that poorly?", "time": 58012}, {"__typename": "Cue", "text": "Some people find it obvious\nthat building something smarter than us", "time": 60431}, {"__typename": "Cue", "text": "that we don't understand might go badly.", "time": 63601}, {"__typename": "Cue", "text": "Others come in with a very wide range\nof hopeful thoughts", "time": 65937}, {"__typename": "Cue", "text": "about how it might possibly go well.", "time": 69857}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Even if I had 20 minutes for this talk\nand months to prepare it,", "time": 72777}, {"__typename": "Cue", "text": "I would not be able to refute\nall the ways people find to imagine", "time": 76155}, {"__typename": "Cue", "text": "that things might go well.", "time": 79242}, {"__typename": "Cue", "text": "But I will say that there is no\nstandard scientific consensus", "time": 80952}, {"__typename": "Cue", "text": "for how things will go well.", "time": 85540}, {"__typename": "Cue", "text": "There is no hope\nthat has been widely persuasive", "time": 87208}, {"__typename": "Cue", "text": "and stood up to skeptical examination.", "time": 89502}, {"__typename": "Cue", "text": "There is nothing resembling a real\nengineering plan for us surviving", "time": 92088}, {"__typename": "Cue", "text": "that I could critique.", "time": 96509}, {"__typename": "Cue", "text": "This is not a good place\nin which to find ourselves.", "time": 98261}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "If I had more time,", "time": 101013}, {"__typename": "Cue", "text": "I'd try to tell you\nabout the predictable reasons", "time": 102223}, {"__typename": "Cue", "text": "why the current paradigm will not work", "time": 104559}, {"__typename": "Cue", "text": "to build a superintelligence\nthat likes you", "time": 106561}, {"__typename": "Cue", "text": "or is friends with you,\nor that just follows orders.", "time": 109063}, {"__typename": "Cue", "text": "Why, if you press \"thumbs up\"\nwhen humans think that things went right", "time": 113109}, {"__typename": "Cue", "text": "or \"thumbs down\" when another AI system\nthinks that they went wrong,", "time": 117530}, {"__typename": "Cue", "text": "you do not get a mind\nthat wants nice things", "time": 121284}, {"__typename": "Cue", "text": "in a way that generalizes well\noutside the training distribution", "time": 124787}, {"__typename": "Cue", "text": "to where the AI is smarter\nthan the trainers.", "time": 128833}, {"__typename": "Cue", "text": "You can search for \"Yudkowsky\nlist of lethalities\" for more.", "time": 132170}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 137300}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "But to worry, you do not\nneed to believe me", "time": 139093}, {"__typename": "Cue", "text": "about exact predictions\nof exact disasters.", "time": 141304}, {"__typename": "Cue", "text": "You just need to expect that things\nare not going to work great", "time": 144223}, {"__typename": "Cue", "text": "on the first really serious,\nreally critical try", "time": 147226}, {"__typename": "Cue", "text": "because an AI system\nsmart enough to be truly dangerous", "time": 150313}, {"__typename": "Cue", "text": "was meaningfully different\nfrom AI systems stupider than that.", "time": 153858}, {"__typename": "Cue", "text": "My prediction is that this ends up with us\nfacing down something smarter than us", "time": 157403}, {"__typename": "Cue", "text": "that does not want what we want,", "time": 162450}, {"__typename": "Cue", "text": "that does not want anything we recognize\nas valuable or meaningful.", "time": 164202}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I cannot predict exactly how a conflict\nbetween humanity and a smarter AI would go", "time": 168748}, {"__typename": "Cue", "text": "for the same reason I can't predict\nexactly how you would lose a chess game", "time": 173377}, {"__typename": "Cue", "text": "to one of the current top\nAI chess programs, let's say Stockfish.", "time": 177256}, {"__typename": "Cue", "text": "If I could predict exactly\nwhere Stockfish could move,", "time": 181469}, {"__typename": "Cue", "text": "I could play chess that well myself.", "time": 185056}, {"__typename": "Cue", "text": "I can't predict exactly\nhow you'll lose to Stockfish,", "time": 187642}, {"__typename": "Cue", "text": "but I can predict who wins the game.", "time": 190144}, {"__typename": "Cue", "text": "I do not expect something actually smart\nto attack us with marching robot armies", "time": 192897}, {"__typename": "Cue", "text": "with glowing red eyes", "time": 197360}, {"__typename": "Cue", "text": "where there could be a fun movie\nabout us fighting them.", "time": 198903}, {"__typename": "Cue", "text": "I expect an actually smarter\nand uncaring entity", "time": 202031}, {"__typename": "Cue", "text": "will figure out strategies\nand technologies", "time": 204575}, {"__typename": "Cue", "text": "that can kill us quickly\nand reliably and then kill us.", "time": 206619}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I am not saying that the problem\nof aligning superintelligence", "time": 210957}, {"__typename": "Cue", "text": "is unsolvable in principle.", "time": 213918}, {"__typename": "Cue", "text": "I expect we could figure it out\nwith unlimited time and unlimited retries,", "time": 215670}, {"__typename": "Cue", "text": "which the usual process of science\nassumes that we have.", "time": 220591}, {"__typename": "Cue", "text": "The problem here is the part\nwhere we don't get to say,", "time": 224804}, {"__typename": "Cue", "text": "\u201cHa ha, whoops, that sure didn\u2019t work.", "time": 227682}, {"__typename": "Cue", "text": "That clever idea that used to work\non earlier systems", "time": 230017}, {"__typename": "Cue", "text": "sure broke down when the AI\ngot smarter, smarter than us.\u201d", "time": 233854}, {"__typename": "Cue", "text": "We do not get to learn\nfrom our mistakes and try again", "time": 238067}, {"__typename": "Cue", "text": "because everyone is already dead.", "time": 240653}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "It is a large ask", "time": 243572}, {"__typename": "Cue", "text": "to get an unprecedented scientific\nand engineering challenge", "time": 246200}, {"__typename": "Cue", "text": "correct on the first critical try.", "time": 249203}, {"__typename": "Cue", "text": "Humanity is not approaching\nthis issue with remotely", "time": 251580}, {"__typename": "Cue", "text": "the level of seriousness\nthat would be required.", "time": 254667}, {"__typename": "Cue", "text": "Some of the people leading these efforts", "time": 257420}, {"__typename": "Cue", "text": "have spent the last decade not denying", "time": 259380}, {"__typename": "Cue", "text": "that creating a superintelligence\nmight kill everyone,", "time": 261882}, {"__typename": "Cue", "text": "but joking about it.", "time": 264802}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We are very far behind.", "time": 266679}, {"__typename": "Cue", "text": "This is not a gap\nwe can overcome in six months,", "time": 268597}, {"__typename": "Cue", "text": "given a six-month moratorium.", "time": 270933}, {"__typename": "Cue", "text": "If we actually try\nto do this in real life,", "time": 273185}, {"__typename": "Cue", "text": "we are all going to die.", "time": 275730}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "People say to me at this point,\nwhat's your ask?", "time": 277898}, {"__typename": "Cue", "text": "I do not have any realistic plan,", "time": 281193}, {"__typename": "Cue", "text": "which is why I spent the last two decades", "time": 282820}, {"__typename": "Cue", "text": "trying and failing to end up\nanywhere but here.", "time": 284822}, {"__typename": "Cue", "text": "My best bad take is that we need\nan international coalition", "time": 288409}, {"__typename": "Cue", "text": "banning large AI training runs,", "time": 292121}, {"__typename": "Cue", "text": "including extreme\nand extraordinary measures", "time": 294373}, {"__typename": "Cue", "text": "to have that ban be actually\nand universally effective,", "time": 297752}, {"__typename": "Cue", "text": "like tracking all GPU sales,", "time": 301005}, {"__typename": "Cue", "text": "monitoring all the data centers,", "time": 303424}, {"__typename": "Cue", "text": "being willing to risk\na shooting conflict between nations", "time": 305551}, {"__typename": "Cue", "text": "in order to destroy\nan unmonitored data center", "time": 308304}, {"__typename": "Cue", "text": "in a non-signatory country.", "time": 311057}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I say this, not expecting\nthat to actually happen.", "time": 313976}, {"__typename": "Cue", "text": "I say this expecting that we all just die.", "time": 317605}, {"__typename": "Cue", "text": "But it is not my place\nto just decide on my own", "time": 321275}, {"__typename": "Cue", "text": "that humanity will choose to die,", "time": 324570}, {"__typename": "Cue", "text": "to the point of not bothering \nto warn anyone.", "time": 326822}, {"__typename": "Cue", "text": "I have heard that people\noutside the tech industry", "time": 329700}, {"__typename": "Cue", "text": "are getting this point\nfaster than people inside it.", "time": 332078}, {"__typename": "Cue", "text": "Maybe humanity wakes up one morning\nand decides to live.", "time": 334747}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Thank you for coming to my brief TED talk.", "time": 339502}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 341545}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Applause and cheers)", "time": 343172}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Chris Anderson: So, Eliezer, thank you\nfor coming and giving that.", "time": 352598}, {"__typename": "Cue", "text": "It seems like what you're raising\nthe alarm about is that like,", "time": 357019}, {"__typename": "Cue", "text": "for this to happen, for an AI\nto basically destroy humanity,", "time": 361023}, {"__typename": "Cue", "text": "it has to break out, escape controls\nof the internet and, you know,", "time": 364985}, {"__typename": "Cue", "text": "start commanding actual\nreal-world resources.", "time": 370157}, {"__typename": "Cue", "text": "You say you can't predict\nhow that will happen,", "time": 373077}, {"__typename": "Cue", "text": "but just paint one or two possibilities.", "time": 375329}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Eliezer Yudkowsky:\nOK, so why is this hard?", "time": 378833}, {"__typename": "Cue", "text": "First, because you can't predict exactly\nwhere a smarter chess program will move.", "time": 381627}, {"__typename": "Cue", "text": "Maybe even more importantly than that,", "time": 385464}, {"__typename": "Cue", "text": "imagine sending the design\nfor an air conditioner", "time": 387383}, {"__typename": "Cue", "text": "back to the 11th century.", "time": 390219}, {"__typename": "Cue", "text": "Even if they -- if it\u2019s enough\ndetail for them to build it,", "time": 392138}, {"__typename": "Cue", "text": "they will be surprised\nwhen cold air comes out", "time": 395307}, {"__typename": "Cue", "text": "because the air conditioner will use\nthe temperature-pressure relation", "time": 398060}, {"__typename": "Cue", "text": "and they don't know\nabout that law of nature.", "time": 401772}, {"__typename": "Cue", "text": "So if you want me to sketch\nwhat a superintelligence might do,", "time": 404275}, {"__typename": "Cue", "text": "I can go deeper and deeper into places", "time": 408946}, {"__typename": "Cue", "text": "where we think there are predictable\ntechnological advancements", "time": 411323}, {"__typename": "Cue", "text": "that we haven't figured out yet.", "time": 414285}, {"__typename": "Cue", "text": "And as I go deeper, it will get\nharder and harder to follow.", "time": 415911}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "It could be super persuasive.", "time": 418747}, {"__typename": "Cue", "text": "That's relatively easy to understand.", "time": 420749}, {"__typename": "Cue", "text": "We do not understand exactly\nhow the brain works,", "time": 422626}, {"__typename": "Cue", "text": "so it's a great place to exploit\nlaws of nature that we do not know about.", "time": 425212}, {"__typename": "Cue", "text": "Rules of the environment,", "time": 428757}, {"__typename": "Cue", "text": "invent new technologies beyond that.", "time": 430301}, {"__typename": "Cue", "text": "Can you build a synthetic virus\nthat gives humans a cold", "time": 433304}, {"__typename": "Cue", "text": "and then a bit of neurological change\nand they're easier to persuade?", "time": 437224}, {"__typename": "Cue", "text": "Can you build your own synthetic biology,", "time": 441437}, {"__typename": "Cue", "text": "synthetic cyborgs?", "time": 444815}, {"__typename": "Cue", "text": "Can you blow straight past that", "time": 446442}, {"__typename": "Cue", "text": "to covalently bonded\nequivalents of biology,", "time": 448486}, {"__typename": "Cue", "text": "where instead of proteins that fold up\nand are held together by static cling,", "time": 452531}, {"__typename": "Cue", "text": "you've got things that go down\nmuch sharper potential energy gradients", "time": 456285}, {"__typename": "Cue", "text": "and are bonded together?", "time": 459705}, {"__typename": "Cue", "text": "People have done advanced design work\nabout this sort of thing", "time": 461081}, {"__typename": "Cue", "text": "for artificial red blood cells\nthat could hold 100 times as much oxygen", "time": 464668}, {"__typename": "Cue", "text": "if they were using tiny\nsapphire vessels to store the oxygen.", "time": 468589}, {"__typename": "Cue", "text": "There's lots and lots\nof room above biology,", "time": 472384}, {"__typename": "Cue", "text": "but it gets harder and harder\nto understand.", "time": 474970}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "CA: So what I hear you saying", "time": 478015}, {"__typename": "Cue", "text": "is that these terrifying\npossibilities there", "time": 479600}, {"__typename": "Cue", "text": "but your real guess is that AIs will work\nout something more devious than that.", "time": 481936}, {"__typename": "Cue", "text": "Is that really a likely\npathway in your mind?", "time": 487066}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "EY: Which part?", "time": 490903}, {"__typename": "Cue", "text": "That they're smarter\nthan I am? Absolutely.", "time": 492112}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "CA: Not that they're smarter,", "time": 494156}, {"__typename": "Cue", "text": "but why would they want\nto go in that direction?", "time": 495574}, {"__typename": "Cue", "text": "Like, AIs don't have our feelings of\nsort of envy and jealousy and anger", "time": 498619}, {"__typename": "Cue", "text": "and so forth.", "time": 504083}, {"__typename": "Cue", "text": "So why might they go in that direction?", "time": 505251}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "EY: Because it's convergently implied\nby almost any of the strange,", "time": 507711}, {"__typename": "Cue", "text": "inscrutable things that they\nmight end up wanting", "time": 512007}, {"__typename": "Cue", "text": "as a result of gradient descent", "time": 515427}, {"__typename": "Cue", "text": "on these \"thumbs up\"\nand \"thumbs down\" things internally.", "time": 517179}, {"__typename": "Cue", "text": "If all you want is to make tiny\nlittle molecular squiggles", "time": 521100}, {"__typename": "Cue", "text": "or that's like, one component\nof what you want,", "time": 525062}, {"__typename": "Cue", "text": "but it's a component that never saturates,\nyou just want more and more of it,", "time": 527565}, {"__typename": "Cue", "text": "the same way that we would want\nmore and more galaxies filled with life", "time": 531193}, {"__typename": "Cue", "text": "and people living happily ever after.", "time": 534530}, {"__typename": "Cue", "text": "Anything that just keeps going,", "time": 536365}, {"__typename": "Cue", "text": "you just want to use more\nand more material for that,", "time": 538033}, {"__typename": "Cue", "text": "that could kill everyone\non Earth as a side effect.", "time": 541120}, {"__typename": "Cue", "text": "It could kill us because it doesn't want\nus making other superintelligences", "time": 543789}, {"__typename": "Cue", "text": "to compete with it.", "time": 547376}, {"__typename": "Cue", "text": "It could kill us because it's using up\nall the chemical energy on earth", "time": 548544}, {"__typename": "Cue", "text": "and we contain some\nchemical potential energy.", "time": 552965}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "CA: So some people in the AI world worry\nthat your views are strong enough", "time": 555551}, {"__typename": "Cue", "text": "and they would say extreme enough", "time": 561807}, {"__typename": "Cue", "text": "that you're willing to advocate\nextreme responses to it.", "time": 563392}, {"__typename": "Cue", "text": "And therefore, they worry\nthat you could be, you know,", "time": 566562}, {"__typename": "Cue", "text": "in one sense, a very destructive figure.", "time": 570024}, {"__typename": "Cue", "text": "Do you draw the line yourself\nin terms of the measures", "time": 571984}, {"__typename": "Cue", "text": "that we should take\nto stop this happening?", "time": 575195}, {"__typename": "Cue", "text": "Or is actually anything\njustifiable to stop", "time": 577990}, {"__typename": "Cue", "text": "the scenarios you're talking\nabout happening?", "time": 581243}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "EY: I don't think that \"anything\" works.", "time": 584330}, {"__typename": "Cue", "text": "I think that this takes state actors", "time": 587583}, {"__typename": "Cue", "text": "and international agreements", "time": 592004}, {"__typename": "Cue", "text": "and all international agreements\nby their nature,", "time": 594798}, {"__typename": "Cue", "text": "tend to ultimately be backed by force", "time": 598052}, {"__typename": "Cue", "text": "on the signatory countries\nand on the non-signatory countries,", "time": 599970}, {"__typename": "Cue", "text": "which is a more extreme measure.", "time": 603390}, {"__typename": "Cue", "text": "I have not proposed that individuals\nrun out and use violence,", "time": 606352}, {"__typename": "Cue", "text": "and I think that the killer argument\nfor that is that it would not work.", "time": 609355}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "CA: Well, you are definitely not\nthe only person to propose", "time": 614985}, {"__typename": "Cue", "text": "that what we need is some kind\nof international reckoning here", "time": 617946}, {"__typename": "Cue", "text": "on how to manage this going forward.", "time": 621992}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Thank you so much\nfor coming here to TED, Eliezer.", "time": 624036}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Applause)", "time": 626497}]}]}, "video": {"__typename": "Video", "id": "114533", "talkExtras": {"__typename": "TalkExtras", "footnotes": [{"__typename": "Footnote", "author": null, "annotation": "> \"Since 2001, I have been working on what we would now call the problem of aligning artificial general intelligence: how to shape the preferences and behavior of a powerful artificial mind such that it does not kill everyone. I more or less founded the field two decades ago, when nobody else considered it rewarding enough to work on.\"\r\n\r\nClarification: The speaker has been hugely influential in technical discussions of AI alignment, though questions on the subject have been raised since at least the 1950s with, for example, the work of Norbert Wiener. See [here](https://www.nature.com/articles/s42256-019-0100-x) and [here](https://link.springer.com/article/10.1007/s11023-020-09539-2).", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "00:01", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"Can you blow straight past that to covalently bonded equivalents of biology, where instead of proteins that fold up and are held together by static cling, you've got things that go down much sharper potential energy gradients and are bonded together? People have done advanced design work about this sort of thing ...\"\r\n\r\nClarification: Proteins are formed by a chain of amino acids covalently bonded into that chain, which then fold up into place according to van der Waals forces, electrostatic attractions and repulsions generally weaker than covalent bonds; calling this \"static cling\" is only a metaphor. For more about protein structure, see [here](https://www.nature.com/scitable/topicpage/protein-structure-14122136/).", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "7:27", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"... for artificial red blood cells that could hold 100 times as much oxygen if they were using tiny sapphire vessels to store the oxygen.\"\r\n\r\nClarification: There has been a range of estimates in the possible efficiency of oxygen delivery by such artificial red blood cells, or \"respirocytes,\" with some estimates calculating they can carry between 200-10,000 times more oxygen. For more, see [here](https://www.researchgate.net/publication/258927053_Nanotechnology_Revolution_Respirocytes_And_Its_Application_In_Life_Sciences) and [here](https://www.sciencedirect.com/science/article/abs/pii/S037712370680016X).", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "7:45", "title": null, "category": "note"}]}}}, "commentsEnabled": true, "commentsLoggedInOnly": true}, "language": "en", "messages": {}, "responseCode": 200, "__N_SSP": true}