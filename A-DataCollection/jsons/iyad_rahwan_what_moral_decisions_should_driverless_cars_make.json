{"pageProps": {"talksPageBanner": {"banner": {"title": "TP TEDLive 9/28/23", "slug": "tp-tedlive-9-28-23", "bannerLocation": "talks", "displayToExistingMembers": true, "mainContentHeadline": "Experience the TEDWomen conference from anywhere", "mainContent": "Don't miss out! Be one of the first to see our powerful new talks. ", "buttonLabel": "Count me in", "buttonLink": "https://membership.ted.com/tedwomen-live?utm_medium=website&utm_source=talkpage&utm_campaign=membership-ted&utm_content=09282023-tedlivetp", "showButtonIcon": false, "backgroundColor": "#000000", "textColor": "#FFFFFF", "useBackgroundGradient": false, "imageMobileBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4gxlFyoebOJrZojA12T8oX", "type": "Asset", "createdAt": "2023-09-28T20:19:28.480Z", "updatedAt": "2023-09-28T20:19:28.480Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Portrait Talks (3)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4gxlFyoebOJrZojA12T8oX/bfca75421f299110dacc3d9ed806f94d/TED_Tech_Jun_12_Tablet_Portrait_Talks__3_.png", "details": {"size": 468918, "image": {"width": 1483, "height": 236}}, "fileName": "TED_Tech_Jun_12_Tablet_Portrait_Talks (3).png", "contentType": "image/png"}}}, "imageTabletBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "ObeWsCx1H7GEtlIkKtvyF", "type": "Asset", "createdAt": "2023-09-28T20:19:28.484Z", "updatedAt": "2023-09-28T20:19:28.484Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Landscape Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/ObeWsCx1H7GEtlIkKtvyF/c246b94cd6fadb4394e2b8d2a5c74f0f/TED_Tech_Jun_12_Tablet_Landscape_Talks__5_.png", "details": {"size": 519237, "image": {"width": 2038, "height": 320}}, "fileName": "TED_Tech_Jun_12_Tablet_Landscape_Talks (5).png", "contentType": "image/png"}}}, "imageDesktopBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4mF9JrHls8kG41J85Bg5ZW", "type": "Asset", "createdAt": "2023-09-28T20:19:28.486Z", "updatedAt": "2023-09-28T20:19:28.486Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Desktop Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4mF9JrHls8kG41J85Bg5ZW/621f89a67d4cdc8bb0ddac22065eab6c/TED_Tech_Jun_12_Desktop_Talks__6_.png", "details": {"size": 515590, "image": {"width": 1203, "height": 328}}, "fileName": "TED_Tech_Jun_12_Desktop_Talks (6).png", "contentType": "image/png"}}}, "imageXLBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4OOqb4MoXPyzcuWcMJdjVn", "type": "Asset", "createdAt": "2023-09-28T20:21:34.825Z", "updatedAt": "2023-09-28T20:21:34.825Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Mobile Talks (7)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4OOqb4MoXPyzcuWcMJdjVn/cfa6e256f33e3ed7bd208289f391d750/TED_Tech_Jun_12_Mobile_Talks__7_.png", "details": {"size": 451422, "image": {"width": 1121, "height": 265}}, "fileName": "TED_Tech_Jun_12_Mobile_Talks (7).png", "contentType": "image/png"}}}}, "status": "published"}, "preview": false, "shortenedUrl": "https://go.ted.com/6ZKL", "action": null, "videoData": {"__typename": "Video", "id": "2824", "slug": "iyad_rahwan_what_moral_decisions_should_driverless_cars_make", "title": "What moral decisions should driverless cars make?", "socialTitle": "What moral decisions should driverless cars make?", "presenterDisplayName": "Iyad Rahwan", "internalLanguageCode": "en", "commentsEnabled": false, "commentsLoggedInOnly": false, "recordedOn": "2016-09-29", "curatorApproved": true, "viewedCount": 1276125, "duration": 806, "publishedAt": "2017-08-22T19:40:47Z", "topics": {"__typename": "TopicConnection", "nodes": [{"__typename": "Topic", "id": "10", "name": "technology", "slug": "technology"}, {"__typename": "Topic", "id": "30", "name": "transportation", "slug": "transportation"}, {"__typename": "Topic", "id": "53", "name": "innovation", "slug": "innovation"}, {"__typename": "Topic", "id": "184", "name": "AI", "slug": "ai"}, {"__typename": "Topic", "id": "204", "name": "law", "slug": "law"}, {"__typename": "Topic", "id": "273", "name": "TEDx", "slug": "tedx"}, {"__typename": "Topic", "id": "554", "name": "driverless cars", "slug": "driverless+cars"}, {"__typename": "Topic", "id": "5795", "name": "ethics", "slug": "ethics"}]}, "talkExtras": {"__typename": "TalkExtras", "recommendations": [{"__typename": "Recommendation", "blurb": "Further reading curated by Iyad Rahwan.", "recLists": [{"__typename": "RecommendationList", "title": "", "description": "", "recItems": [{"__typename": "RecommendationItem", "blurb": "In this *New York Times* article, my collaborators Azim Shariff, Jean-Francois and I make a case for the importance of understanding the psychological barriers facing trust in autonomous vehicles. If we ignore those barriers and focus only on the engineering challenges, we risk delaying the adoption of driverless cars even if they are much safer.", "eyebrow": "", "headline": "\"Whose Life Should Your Car Save?\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "https://www.nytimes.com/2016/11/06/opinion/sunday/whose-life-should-your-car-save.html?_r=0", "note": "Azim Shariff, Iyad Rahwan and Jean-Fran\u00e7ois Bonnefon\r\n*New York Times*, 2016"}, {"__typename": "RecommendationItem", "blurb": "Patrick explores the main critiques of the Trolley Problem paradigm for thinking about driverless car ethics. He explores why the through experiments can be useful, despite being overly simplistic, or perhaps precisely because of that.", "eyebrow": "", "headline": "\"Robot Cars And Fake Ethical Dilemmas\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "https://www.forbes.com/sites/patricklin/2017/04/03/robot-cars-and-fake-ethical-dilemmas/#34b4192913a2", "note": "Patrick Lin\r\n*Forbes*, 2017"}, {"__typename": "RecommendationItem", "blurb": "Written by two philosophers, this book explores the broader philosophical and ethical challenges of building moral Artificial Intelligence. It shows the standard ethical theories do not seem adequate, and more socially engaged and engaging robots will be needed.", "eyebrow": "", "headline": "*Moral Machines: Teaching Robots Right from Wrong*", "isPdf": false, "label": "READ_BOOK", "linkUrl": "https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "note": "Wendell Wallach and Colin Allen\r\nOxford University Press, 2010"}, {"__typename": "RecommendationItem", "blurb": "This article reports the detailed experiments we ran on the ethics of autonomous vehicles, and which I summarize in the talk. You can find a free pre-print of the research paper [here](https://arxiv.org/abs/1510.03346).", "eyebrow": "", "headline": "\"The Social Dilemma of Autonomous Vehicles\"", "isPdf": false, "label": "READ_ARTICLE", "linkUrl": "http://science.sciencemag.org/content/352/6293/1573.full", "note": "Jean-Fran\u00e7ois Bonnefon, Azim Shariff, Iyad Rahwan\r\n*Science*, 2016"}]}]}], "takeAction": [{"__typename": "TakeActionModule", "blurb": "**Participate** in research on the hypothetical ethical dilemmas faced driverless cars and learn more about the difficulties faced by programmers of artificial intelligence systems.", "endAt": null, "eyebrow": "", "linkUrl": "http://moralmachine.mit.edu/", "published": true, "startAt": null, "status": "APPROVED", "verb": "participate", "visibleUrl": "moralmachine.mit.edu"}], "learnModules": []}, "primaryImageSet": [{"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/738fd43c-a227-4859-ab12-2d666a1a63ac/IyadRahwan_2016X-embed.jpg", "aspectRatioName": "16x9"}, {"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/ccf23d63-1261-4338-8e8b-365c52237952/IyadRahwan_2016X-stageshot.jpg", "aspectRatioName": "4x3"}], "relatedVideos": [{"__typename": "Video", "slug": "wanis_kabbaj_what_a_driverless_world_could_look_like", "id": "2609"}, {"__typename": "Video", "slug": "patrick_lin_the_ethical_dilemma_of_self_driving_cars", "id": "2760"}, {"__typename": "Video", "slug": "eleanor_nelsen_would_you_sacrifice_one_person_to_save_five", "id": "2766"}, {"__typename": "Video", "slug": "chris_urmson_how_a_driverless_car_sees_the_road", "id": "2291"}, {"__typename": "Video", "slug": "travis_kalanick_uber_s_plan_to_get_more_people_into_fewer_cars", "id": "2443"}, {"__typename": "Video", "slug": "jennifer_healey_if_cars_could_talk_accidents_might_be_avoidable", "id": "1724"}], "customContentDetails": {"__typename": "CustomContentDetails", "partnerName": null}, "speakers": {"__typename": "AcmeSpeakerConnection", "nodes": [{"__typename": "AcmeSpeaker", "photoUrl": "https://pe.tedcdn.com/images/ted/6c472ca8216c163424e1a4b8b3f259a7d4c38f7b_254x191.jpg", "firstname": "Iyad", "middlename": "", "lastname": "Rahwan", "description": "Computational social scientist", "isLive": true, "title": "", "whatOthersSay": "", "whoTheyAre": "Iyad Rahwan's work lies at the intersection of the computer and social sciences, with a focus on collective intelligence, large-scale cooperation and the social aspects of artificial intelligence.", "whyListen": "<p>Iyad Rahwan is the AT&amp;T Career Development Professor and an associate&nbsp;professor of media&nbsp;arts &amp; sciences at the&nbsp;<a href=\"https://www.media.mit.edu/\" target=\"_blank\">MIT Media Lab</a>, where he leads the&nbsp;<a href=\"https://www.media.mit.edu/groups/scalable-cooperation/overview/\" target=\"_blank\">Scalable Cooperation</a>&nbsp;group. A native of Aleppo, Syria, Rahwan holds a PhD. from the&nbsp;<a href=\"http://www.unimelb.edu.au/\" target=\"_blank\">University of Melbourne</a>, Australia and is an affiliate faculty at the&nbsp;<a href=\"https://idss.mit.edu/\" target=\"_blank\">MIT Institute of Data, Systems and Society (IDSS)</a>. He led the winning team in the US State Department&#39;s&nbsp;<a href=\"https://www.scientificamerican.com/article/crowdsourcing-in-manhunts-can-work/\" target=\"_blank\">Tag Challenge</a>,&nbsp;using social media to locate individuals in remote cities within 12 hours using only their mug shots. Recently he crowdsourced 30 million decisions from people worldwide about the&nbsp;<a href=\"https://www.nytimes.com/2016/11/06/opinion/sunday/whose-life-should-your-car-save.html\" target=\"_blank\">ethics of AI systems</a>. Rahwan&#39;s work appeared in major academic journals, including <em>Science</em> and <em>PNAS</em>, and features regularly in major media outlets, including the <em>New York Times</em>, <em>The Economist&nbsp;</em>and the <em>Wall Street Journal</em>.</p><p>(Photo: Victoriano Izquierdo)</p>", "slug": "iyad_rahwan"}]}, "description": "Should your driverless car kill you if it means saving five pedestrians? In this primer on the social dilemmas of driverless cars, Iyad Rahwan explores how the technology will challenge our morality and explains his work collecting data from real people on the ethical trade-offs we're willing (and not willing) to make.", "socialDescription": "Should your driverless car kill you if it means saving five pedestrians? In this primer on the social dilemmas of driverless cars, Iyad Rahwan explores how the technology will challenge our morality and explains his work collecting data from real people on the ethical trade-offs we're willing (and not willing) to make.", "partnerName": null, "playerData": "{\"id\":\"2824\",\"mediaIdentifier\":\"consus-pm6196-im2346\",\"mediaProjectVersionIdentifier\":\"consus-pm6196-im2346\",\"duration\":815,\"languages\":[{\"languageName\":\"English\",\"endonym\":\"English\",\"languageCode\":\"en\",\"ianaCode\":\"en\",\"isRtl\":false},{\"languageName\":\"Arabic\",\"endonym\":\"\u0627\u0644\u0639\u0631\u0628\u064a\u0629\",\"languageCode\":\"ar\",\"ianaCode\":\"ar\",\"isRtl\":true},{\"languageName\":\"Portuguese, Brazilian\",\"endonym\":\"Portugu\u00eas brasileiro\",\"languageCode\":\"pt-br\",\"ianaCode\":\"pt-BR\",\"isRtl\":false},{\"languageName\":\"Persian\",\"endonym\":\"\u0641\u0627\u0631\u0633\u0649\",\"languageCode\":\"fa\",\"ianaCode\":\"fa\",\"isRtl\":true},{\"languageName\":\"Russian\",\"endonym\":\"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\",\"languageCode\":\"ru\",\"ianaCode\":\"ru\",\"isRtl\":false},{\"languageName\":\"Hebrew\",\"endonym\":\"\u05e2\u05d1\u05e8\u05d9\u05ea\",\"languageCode\":\"he\",\"ianaCode\":\"he\",\"isRtl\":true},{\"languageName\":\"Portuguese\",\"endonym\":\"Portugu\u00eas de Portugal\",\"languageCode\":\"pt\",\"ianaCode\":\"pt\",\"isRtl\":false},{\"languageName\":\"German\",\"endonym\":\"Deutsch\",\"languageCode\":\"de\",\"ianaCode\":\"de\",\"isRtl\":false},{\"languageName\":\"French\",\"endonym\":\"Fran\u00e7ais\",\"languageCode\":\"fr\",\"ianaCode\":\"fr\",\"isRtl\":false},{\"languageName\":\"Turkish\",\"endonym\":\"T\u00fcrk\u00e7e\",\"languageCode\":\"tr\",\"ianaCode\":\"tr\",\"isRtl\":false},{\"languageName\":\"Dutch\",\"endonym\":\"Nederlands\",\"languageCode\":\"nl\",\"ianaCode\":\"nl\",\"isRtl\":false},{\"languageName\":\"Hungarian\",\"endonym\":\"Magyar\",\"languageCode\":\"hu\",\"ianaCode\":\"hu\",\"isRtl\":false},{\"languageName\":\"Spanish\",\"endonym\":\"Espa\u00f1ol\",\"languageCode\":\"es\",\"ianaCode\":\"es\",\"isRtl\":false},{\"languageName\":\"Korean\",\"endonym\":\"\ud55c\uad6d\uc5b4\",\"languageCode\":\"ko\",\"ianaCode\":\"ko\",\"isRtl\":false},{\"languageName\":\"Lithuanian\",\"endonym\":\"Lietuvi\u0173 kalba\",\"languageCode\":\"lt\",\"ianaCode\":\"lt\",\"isRtl\":false},{\"languageName\":\"Chinese, Simplified\",\"endonym\":\"\u4e2d\u6587 (\u7b80\u4f53)\",\"languageCode\":\"zh-cn\",\"ianaCode\":\"zh-Hans\",\"isRtl\":false},{\"languageName\":\"Ukrainian\",\"endonym\":\"\u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\",\"languageCode\":\"uk\",\"ianaCode\":\"uk\",\"isRtl\":false},{\"languageName\":\"Chinese, Traditional\",\"endonym\":\"\u4e2d\u6587 (\u7e41\u9ad4)\",\"languageCode\":\"zh-tw\",\"ianaCode\":\"zh-Hant\",\"isRtl\":false},{\"languageName\":\"Japanese\",\"endonym\":\"\u65e5\u672c\u8a9e\",\"languageCode\":\"ja\",\"ianaCode\":\"ja\",\"isRtl\":false},{\"languageName\":\"Croatian\",\"endonym\":\"Hrvatski\",\"languageCode\":\"hr\",\"ianaCode\":\"hr\",\"isRtl\":false},{\"languageName\":\"Italian\",\"endonym\":\"Italiano\",\"languageCode\":\"it\",\"ianaCode\":\"it\",\"isRtl\":false},{\"languageName\":\"Vietnamese\",\"endonym\":\"Ti\u1ebfng Vi\u1ec7t\",\"languageCode\":\"vi\",\"ianaCode\":\"vi\",\"isRtl\":false}],\"nativeLanguage\":\"en\",\"isSubtitleRequired\":false,\"resources\":{\"h264\":[{\"bitrate\":1200,\"file\":\"https://py.tedcdn.com/consus/projects/00/28/82/003/products/2016x-iyad-rahwan-003-fallback-c05adb277ea4b9a0c84f8d4c88a50fa6-1200k.mp4\"}],\"hls\":{\"adUrl\":\"https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTEDxCambridge%26id%3D2824%26tag%3DAI%2Cdriverless%2Bcars%2Claw%2Cinnovation%2Ctechnology%2Cethics%2CTEDx%2Ctransportation%26talk%3Diyad_rahwan_what_moral_decisions_should_driverless_cars_make%26year%3D2016&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D\",\"maiTargeting\":{\"id\":\"2824\",\"talk\":\"iyad_rahwan_what_moral_decisions_should_driverless_cars_make\",\"tag\":\"AI,driverless cars,law,innovation,technology,ethics,TEDx,transportation\",\"year\":\"2016\",\"event\":\"TEDxCambridge\"},\"stream\":\"https://hls.ted.com/project_masters/6196/manifest.m3u8?intro_master_id=2346\",\"metadata\":\"https://hls.ted.com/project_masters/6196/metadata.json?intro_master_id=2346\"}},\"targeting\":{\"id\":\"2824\",\"talk\":\"iyad_rahwan_what_moral_decisions_should_driverless_cars_make\",\"tag\":\"AI,driverless cars,law,innovation,technology,ethics,TEDx,transportation\",\"year\":\"2016\",\"event\":\"TEDxCambridge\"},\"canonical\":\"https://www.ted.com/talks/iyad_rahwan_what_moral_decisions_should_driverless_cars_make\",\"name\":\"Iyad Rahwan: What moral decisions should driverless cars make?\",\"title\":\"What moral decisions should driverless cars make?\",\"speaker\":\"Iyad Rahwan\",\"thumb\":\"https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/738fd43c-a227-4859-ab12-2d666a1a63ac/IyadRahwan_2016X-embed.jpg?quality=89&w=600\",\"slug\":\"iyad_rahwan_what_moral_decisions_should_driverless_cars_make\",\"event\":\"TEDxCambridge\",\"published\":1503430847,\"external\":{\"service\":\"YouTube\",\"code\":\"tb-WdVA4_bo\",\"duration\":816.0,\"start_time\":0.0}}", "videoContext": "TEDxCambridge", "audioInternalLanguageCode": "en", "language": "en", "hasTranslations": true, "featured": true, "type": {"__typename": "TypeOfVideo", "id": "2", "name": "TEDx Talk"}}, "transcriptData": {"translation": {"__typename": "Translation", "id": "116516", "language": {"__typename": "Language", "id": "35", "endonym": "English", "englishName": "English", "internalLanguageCode": "en", "rtl": false}, "reviewer": null, "translator": null, "paragraphs": [{"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Today I'm going to talk\nabout technology and society.", "time": 1000}, {"__typename": "Cue", "text": "The Department of Transport\nestimated that last year", "time": 7040}, {"__typename": "Cue", "text": "35,000 people died\nfrom traffic crashes in the US alone.", "time": 10760}, {"__typename": "Cue", "text": "Worldwide, 1.2 million people\ndie every year in traffic accidents.", "time": 16040}, {"__typename": "Cue", "text": "If there was a way we could eliminate\n90 percent of those accidents,", "time": 21760}, {"__typename": "Cue", "text": "would you support it?", "time": 25880}, {"__typename": "Cue", "text": "Of course you would.", "time": 27720}, {"__typename": "Cue", "text": "This is what driverless car technology\npromises to achieve", "time": 29040}, {"__typename": "Cue", "text": "by eliminating the main\nsource of accidents --", "time": 32720}, {"__typename": "Cue", "text": "human error.", "time": 35560}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Now picture yourself\nin a driverless car in the year 2030,", "time": 37920}, {"__typename": "Cue", "text": "sitting back and watching\nthis vintage TEDxCambridge video.", "time": 43360}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 46840}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "All of a sudden,", "time": 49520}, {"__typename": "Cue", "text": "the car experiences mechanical failure\nand is unable to stop.", "time": 50760}, {"__typename": "Cue", "text": "If the car continues,", "time": 55360}, {"__typename": "Cue", "text": "it will crash into a bunch\nof pedestrians crossing the street,", "time": 57720}, {"__typename": "Cue", "text": "but the car may swerve,", "time": 63080}, {"__typename": "Cue", "text": "hitting one bystander,", "time": 65239}, {"__typename": "Cue", "text": "killing them to save the pedestrians.", "time": 67120}, {"__typename": "Cue", "text": "What should the car do,\nand who should decide?", "time": 70040}, {"__typename": "Cue", "text": "What if instead the car\ncould swerve into a wall,", "time": 73520}, {"__typename": "Cue", "text": "crashing and killing you, the passenger,", "time": 77080}, {"__typename": "Cue", "text": "in order to save those pedestrians?", "time": 80400}, {"__typename": "Cue", "text": "This scenario is inspired\nby the trolley problem,", "time": 83240}, {"__typename": "Cue", "text": "which was invented\nby philosophers a few decades ago", "time": 86960}, {"__typename": "Cue", "text": "to think about ethics.", "time": 90760}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Now, the way we think\nabout this problem matters.", "time": 94120}, {"__typename": "Cue", "text": "We may for example\nnot think about it at all.", "time": 96640}, {"__typename": "Cue", "text": "We may say this scenario is unrealistic,", "time": 99280}, {"__typename": "Cue", "text": "incredibly unlikely, or just silly.", "time": 102680}, {"__typename": "Cue", "text": "But I think this criticism\nmisses the point", "time": 105760}, {"__typename": "Cue", "text": "because it takes\nthe scenario too literally.", "time": 108520}, {"__typename": "Cue", "text": "Of course no accident\nis going to look like this;", "time": 111920}, {"__typename": "Cue", "text": "no accident has two or three options", "time": 114680}, {"__typename": "Cue", "text": "where everybody dies somehow.", "time": 118040}, {"__typename": "Cue", "text": "Instead, the car is going\nto calculate something", "time": 121480}, {"__typename": "Cue", "text": "like the probability of hitting\na certain group of people,", "time": 124080}, {"__typename": "Cue", "text": "if you swerve one direction\nversus another direction,", "time": 129000}, {"__typename": "Cue", "text": "you might slightly increase the risk\nto passengers or other drivers", "time": 132360}, {"__typename": "Cue", "text": "versus pedestrians.", "time": 135840}, {"__typename": "Cue", "text": "It's going to be\na more complex calculation,", "time": 137400}, {"__typename": "Cue", "text": "but it's still going\nto involve trade-offs,", "time": 140480}, {"__typename": "Cue", "text": "and trade-offs often require ethics.", "time": 143840}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We might say then,\n\"Well, let's not worry about this.", "time": 147840}, {"__typename": "Cue", "text": "Let's wait until technology\nis fully ready and 100 percent safe.\"", "time": 150600}, {"__typename": "Cue", "text": "Suppose that we can indeed\neliminate 90 percent of those accidents,", "time": 156520}, {"__typename": "Cue", "text": "or even 99 percent in the next 10 years.", "time": 161080}, {"__typename": "Cue", "text": "What if eliminating\nthe last one percent of accidents", "time": 164920}, {"__typename": "Cue", "text": "requires 50 more years of research?", "time": 168120}, {"__typename": "Cue", "text": "Should we not adopt the technology?", "time": 172400}, {"__typename": "Cue", "text": "That's 60 million people\ndead in car accidents", "time": 174720}, {"__typename": "Cue", "text": "if we maintain the current rate.", "time": 179520}, {"__typename": "Cue", "text": "So the point is,", "time": 182760}, {"__typename": "Cue", "text": "waiting for full safety is also a choice,", "time": 184000}, {"__typename": "Cue", "text": "and it also involves trade-offs.", "time": 187640}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "People online on social media\nhave been coming up with all sorts of ways", "time": 191560}, {"__typename": "Cue", "text": "to not think about this problem.", "time": 195920}, {"__typename": "Cue", "text": "One person suggested\nthe car should just swerve somehow", "time": 197960}, {"__typename": "Cue", "text": "in between the passengers --", "time": 201200}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 203360}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "and the bystander.", "time": 204400}, {"__typename": "Cue", "text": "Of course if that's what the car can do,\nthat's what the car should do.", "time": 205680}, {"__typename": "Cue", "text": "We're interested in scenarios\nin which this is not possible.", "time": 209920}, {"__typename": "Cue", "text": "And my personal favorite\nwas a suggestion by a blogger", "time": 213280}, {"__typename": "Cue", "text": "to have an eject button in the car\nthat you press --", "time": 218720}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 221760}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "just before the car self-destructs.", "time": 223000}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 224691}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So if we acknowledge that cars\nwill have to make trade-offs on the road,", "time": 227840}, {"__typename": "Cue", "text": "how do we think about those trade-offs,", "time": 234200}, {"__typename": "Cue", "text": "and how do we decide?", "time": 237320}, {"__typename": "Cue", "text": "Well, maybe we should run a survey\nto find out what society wants,", "time": 238920}, {"__typename": "Cue", "text": "because ultimately,", "time": 242080}, {"__typename": "Cue", "text": "regulations and the law\nare a reflection of societal values.", "time": 243560}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So this is what we did.", "time": 248040}, {"__typename": "Cue", "text": "With my collaborators,", "time": 249880}, {"__typename": "Cue", "text": "Jean-Fran\u00e7ois Bonnefon and Azim Shariff,", "time": 251520}, {"__typename": "Cue", "text": "we ran a survey", "time": 253880}, {"__typename": "Cue", "text": "in which we presented people\nwith these types of scenarios.", "time": 255520}, {"__typename": "Cue", "text": "We gave them two options\ninspired by two philosophers:", "time": 258399}, {"__typename": "Cue", "text": "Jeremy Bentham and Immanuel Kant.", "time": 262200}, {"__typename": "Cue", "text": "Bentham says the car\nshould follow utilitarian ethics:", "time": 265600}, {"__typename": "Cue", "text": "it should take the action\nthat will minimize total harm --", "time": 268720}, {"__typename": "Cue", "text": "even if that action will kill a bystander", "time": 272160}, {"__typename": "Cue", "text": "and even if that action\nwill kill the passenger.", "time": 275000}, {"__typename": "Cue", "text": "Immanuel Kant says the car\nshould follow duty-bound principles,", "time": 278120}, {"__typename": "Cue", "text": "like \"Thou shalt not kill.\"", "time": 283120}, {"__typename": "Cue", "text": "So you should not take an action\nthat explicitly harms a human being,", "time": 285480}, {"__typename": "Cue", "text": "and you should let the car take its course", "time": 289960}, {"__typename": "Cue", "text": "even if that's going to harm more people.", "time": 292440}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "What do you think?", "time": 295640}, {"__typename": "Cue", "text": "Bentham or Kant?", "time": 297360}, {"__typename": "Cue", "text": "Here's what we found.", "time": 299760}, {"__typename": "Cue", "text": "Most people sided with Bentham.", "time": 301040}, {"__typename": "Cue", "text": "So it seems that people\nwant cars to be utilitarian,", "time": 304160}, {"__typename": "Cue", "text": "minimize total harm,", "time": 307960}, {"__typename": "Cue", "text": "and that's what we should all do.", "time": 309400}, {"__typename": "Cue", "text": "Problem solved.", "time": 311000}, {"__typename": "Cue", "text": "But there is a little catch.", "time": 313240}, {"__typename": "Cue", "text": "When we asked people\nwhether they would purchase such cars,", "time": 315920}, {"__typename": "Cue", "text": "they said, \"Absolutely not.\"", "time": 319680}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 321320}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "They would like to buy cars\nthat protect them at all costs,", "time": 323640}, {"__typename": "Cue", "text": "but they want everybody else\nto buy cars that minimize harm.", "time": 327560}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 331200}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We've seen this problem before.", "time": 334720}, {"__typename": "Cue", "text": "It's called a social dilemma.", "time": 336600}, {"__typename": "Cue", "text": "And to understand the social dilemma,", "time": 339160}, {"__typename": "Cue", "text": "we have to go a little bit\nback in history.", "time": 341000}, {"__typename": "Cue", "text": "In the 1800s,", "time": 344000}, {"__typename": "Cue", "text": "English economist William Forster Lloyd\npublished a pamphlet", "time": 346600}, {"__typename": "Cue", "text": "which describes the following scenario.", "time": 350360}, {"__typename": "Cue", "text": "You have a group of farmers --", "time": 352600}, {"__typename": "Cue", "text": "English farmers --", "time": 354280}, {"__typename": "Cue", "text": "who are sharing a common land\nfor their sheep to graze.", "time": 355640}, {"__typename": "Cue", "text": "Now, if each farmer\nbrings a certain number of sheep --", "time": 359520}, {"__typename": "Cue", "text": "let's say three sheep --", "time": 362120}, {"__typename": "Cue", "text": "the land will be rejuvenated,", "time": 363640}, {"__typename": "Cue", "text": "the farmers are happy,", "time": 365760}, {"__typename": "Cue", "text": "the sheep are happy,", "time": 367000}, {"__typename": "Cue", "text": "everything is good.", "time": 368640}, {"__typename": "Cue", "text": "Now, if one farmer brings one extra sheep,", "time": 370440}, {"__typename": "Cue", "text": "that farmer will do slightly better,\nand no one else will be harmed.", "time": 373800}, {"__typename": "Cue", "text": "But if every farmer made\nthat individually rational decision,", "time": 379160}, {"__typename": "Cue", "text": "the land will be overrun,\nand it will be depleted", "time": 383840}, {"__typename": "Cue", "text": "to the detriment of all the farmers,", "time": 387360}, {"__typename": "Cue", "text": "and of course,\nto the detriment of the sheep.", "time": 389560}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We see this problem in many places:", "time": 392720}, {"__typename": "Cue", "text": "in the difficulty of managing overfishing,", "time": 397080}, {"__typename": "Cue", "text": "or in reducing carbon emissions\nto mitigate climate change.", "time": 400280}, {"__typename": "Cue", "text": "When it comes to the regulation\nof driverless cars,", "time": 407160}, {"__typename": "Cue", "text": "the common land now\nis basically public safety --", "time": 411080}, {"__typename": "Cue", "text": "that's the common good --", "time": 415440}, {"__typename": "Cue", "text": "and the farmers are the passengers", "time": 417400}, {"__typename": "Cue", "text": "or the car owners who are choosing\nto ride in those cars.", "time": 419400}, {"__typename": "Cue", "text": "And by making the individually\nrational choice", "time": 424960}, {"__typename": "Cue", "text": "of prioritizing their own safety,", "time": 427600}, {"__typename": "Cue", "text": "they may collectively be\ndiminishing the common good,", "time": 430440}, {"__typename": "Cue", "text": "which is minimizing total harm.", "time": 433600}, {"__typename": "Cue", "text": "It's called the tragedy of the commons,", "time": 438320}, {"__typename": "Cue", "text": "traditionally,", "time": 440480}, {"__typename": "Cue", "text": "but I think in the case\nof driverless cars,", "time": 441800}, {"__typename": "Cue", "text": "the problem may be\na little bit more insidious", "time": 444920}, {"__typename": "Cue", "text": "because there is not necessarily\nan individual human being", "time": 447800}, {"__typename": "Cue", "text": "making those decisions.", "time": 451320}, {"__typename": "Cue", "text": "So car manufacturers\nmay simply program cars", "time": 453040}, {"__typename": "Cue", "text": "that will maximize safety\nfor their clients,", "time": 456360}, {"__typename": "Cue", "text": "and those cars may learn\nautomatically on their own", "time": 460080}, {"__typename": "Cue", "text": "that doing so requires slightly\nincreasing risk for pedestrians.", "time": 463080}, {"__typename": "Cue", "text": "So to use the sheep metaphor,", "time": 467520}, {"__typename": "Cue", "text": "it's like we now have electric sheep\nthat have a mind of their own.", "time": 468960}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 472600}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "And they may go and graze\neven if the farmer doesn't know it.", "time": 474080}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So this is what we may call\nthe tragedy of the algorithmic commons,", "time": 478640}, {"__typename": "Cue", "text": "and if offers new types of challenges.", "time": 482640}, {"__typename": "Cue", "text": "Typically, traditionally,", "time": 490520}, {"__typename": "Cue", "text": "we solve these types\nof social dilemmas using regulation,", "time": 492440}, {"__typename": "Cue", "text": "so either governments\nor communities get together,", "time": 495800}, {"__typename": "Cue", "text": "and they decide collectively\nwhat kind of outcome they want", "time": 498560}, {"__typename": "Cue", "text": "and what sort of constraints\non individual behavior", "time": 502320}, {"__typename": "Cue", "text": "they need to implement.", "time": 505000}, {"__typename": "Cue", "text": "And then using monitoring and enforcement,", "time": 507600}, {"__typename": "Cue", "text": "they can make sure\nthat the public good is preserved.", "time": 510240}, {"__typename": "Cue", "text": "So why don't we just,", "time": 513440}, {"__typename": "Cue", "text": "as regulators,", "time": 515039}, {"__typename": "Cue", "text": "require that all cars minimize harm?", "time": 516559}, {"__typename": "Cue", "text": "After all, this is\nwhat people say they want.", "time": 519480}, {"__typename": "Cue", "text": "And more importantly,", "time": 523200}, {"__typename": "Cue", "text": "I can be sure that as an individual,", "time": 524640}, {"__typename": "Cue", "text": "if I buy a car that may\nsacrifice me in a very rare case,", "time": 527760}, {"__typename": "Cue", "text": "I'm not the only sucker doing that", "time": 531640}, {"__typename": "Cue", "text": "while everybody else\nenjoys unconditional protection.", "time": 533320}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "In our survey, we did ask people\nwhether they would support regulation", "time": 537120}, {"__typename": "Cue", "text": "and here's what we found.", "time": 540480}, {"__typename": "Cue", "text": "First of all, people\nsaid no to regulation;", "time": 542360}, {"__typename": "Cue", "text": "and second, they said,", "time": 547280}, {"__typename": "Cue", "text": "\"Well if you regulate cars to do this\nand to minimize total harm,", "time": 548560}, {"__typename": "Cue", "text": "I will not buy those cars.\"", "time": 552520}, {"__typename": "Cue", "text": "So ironically,", "time": 555400}, {"__typename": "Cue", "text": "by regulating cars to minimize harm,", "time": 556800}, {"__typename": "Cue", "text": "we may actually end up with more harm", "time": 560320}, {"__typename": "Cue", "text": "because people may not\nopt into the safer technology", "time": 563040}, {"__typename": "Cue", "text": "even if it's much safer\nthan human drivers.", "time": 566720}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "I don't have the final\nanswer to this riddle,", "time": 570360}, {"__typename": "Cue", "text": "but I think as a starting point,", "time": 573800}, {"__typename": "Cue", "text": "we need society to come together", "time": 575400}, {"__typename": "Cue", "text": "to decide what trade-offs\nwe are comfortable with", "time": 578720}, {"__typename": "Cue", "text": "and to come up with ways\nin which we can enforce those trade-offs.", "time": 582360}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "As a starting point,\nmy brilliant students,", "time": 586520}, {"__typename": "Cue", "text": "Edmond Awad and Sohan Dsouza,", "time": 589080}, {"__typename": "Cue", "text": "built the Moral Machine website,", "time": 591560}, {"__typename": "Cue", "text": "which generates random scenarios at you --", "time": 594200}, {"__typename": "Cue", "text": "basically a bunch\nof random dilemmas in a sequence", "time": 598080}, {"__typename": "Cue", "text": "where you have to choose what\nthe car should do in a given scenario.", "time": 600560}, {"__typename": "Cue", "text": "And we vary the ages and even\nthe species of the different victims.", "time": 605040}, {"__typename": "Cue", "text": "So far we've collected\nover five million decisions", "time": 611040}, {"__typename": "Cue", "text": "by over one million people worldwide", "time": 614760}, {"__typename": "Cue", "text": "from the website.", "time": 618400}, {"__typename": "Cue", "text": "And this is helping us\nform an early picture", "time": 620360}, {"__typename": "Cue", "text": "of what trade-offs\npeople are comfortable with", "time": 622800}, {"__typename": "Cue", "text": "and what matters to them --", "time": 625440}, {"__typename": "Cue", "text": "even across cultures.", "time": 627360}, {"__typename": "Cue", "text": "But more importantly,", "time": 630240}, {"__typename": "Cue", "text": "doing this exercise\nis helping people recognize", "time": 631760}, {"__typename": "Cue", "text": "the difficulty of making those choices", "time": 635160}, {"__typename": "Cue", "text": "and that the regulators\nare tasked with impossible choices.", "time": 638000}, {"__typename": "Cue", "text": "And maybe this will help us as a society\nunderstand the kinds of trade-offs", "time": 643360}, {"__typename": "Cue", "text": "that will be implemented\nultimately in regulation.", "time": 646960}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "And indeed, I was very happy to hear", "time": 650040}, {"__typename": "Cue", "text": "that the first set of regulations", "time": 651800}, {"__typename": "Cue", "text": "that came from\nthe Department of Transport --", "time": 653840}, {"__typename": "Cue", "text": "announced last week --", "time": 656000}, {"__typename": "Cue", "text": "included a 15-point checklist\nfor all carmakers to provide,", "time": 657400}, {"__typename": "Cue", "text": "and number 14 was ethical consideration --", "time": 664000}, {"__typename": "Cue", "text": "how are you going to deal with that.", "time": 667280}, {"__typename": "Cue", "text": "We also have people\nreflect on their own decisions", "time": 671800}, {"__typename": "Cue", "text": "by giving them summaries\nof what they chose.", "time": 674480}, {"__typename": "Cue", "text": "I'll give you one example --", "time": 678440}, {"__typename": "Cue", "text": "I'm just going to warn you\nthat this is not your typical example,", "time": 680120}, {"__typename": "Cue", "text": "your typical user.", "time": 683680}, {"__typename": "Cue", "text": "This is the most sacrificed and the most\nsaved character for this person.", "time": 685080}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 688720}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Some of you may agree with him,", "time": 694680}, {"__typename": "Cue", "text": "or her, we don't know.", "time": 696600}, {"__typename": "Cue", "text": "But this person also seems to slightly\nprefer passengers over pedestrians", "time": 700480}, {"__typename": "Cue", "text": "in their choices", "time": 706640}, {"__typename": "Cue", "text": "and is very happy to punish jaywalking.", "time": 708760}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 711600}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So let's wrap up.", "time": 717320}, {"__typename": "Cue", "text": "We started with the question --\nlet's call it the ethical dilemma --", "time": 718559}, {"__typename": "Cue", "text": "of what the car should do\nin a specific scenario:", "time": 722000}, {"__typename": "Cue", "text": "swerve or stay?", "time": 725080}, {"__typename": "Cue", "text": "But then we realized\nthat the problem was a different one.", "time": 727240}, {"__typename": "Cue", "text": "It was the problem of how to get\nsociety to agree on and enforce", "time": 730000}, {"__typename": "Cue", "text": "the trade-offs they're comfortable with.", "time": 734560}, {"__typename": "Cue", "text": "It's a social dilemma.", "time": 736520}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "In the 1940s, Isaac Asimov\nwrote his famous laws of robotics --", "time": 737800}, {"__typename": "Cue", "text": "the three laws of robotics.", "time": 742840}, {"__typename": "Cue", "text": "A robot may not harm a human being,", "time": 745240}, {"__typename": "Cue", "text": "a robot may not disobey a human being,", "time": 747720}, {"__typename": "Cue", "text": "and a robot may not allow\nitself to come to harm --", "time": 750280}, {"__typename": "Cue", "text": "in this order of importance.", "time": 753560}, {"__typename": "Cue", "text": "But after 40 years or so", "time": 756360}, {"__typename": "Cue", "text": "and after so many stories\npushing these laws to the limit,", "time": 758520}, {"__typename": "Cue", "text": "Asimov introduced the zeroth law", "time": 762280}, {"__typename": "Cue", "text": "which takes precedence above all,", "time": 766000}, {"__typename": "Cue", "text": "and it's that a robot\nmay not harm humanity as a whole.", "time": 768280}, {"__typename": "Cue", "text": "I don't know what this means\nin the context of driverless cars", "time": 772480}, {"__typename": "Cue", "text": "or any specific situation,", "time": 776880}, {"__typename": "Cue", "text": "and I don't know how we can implement it,", "time": 779640}, {"__typename": "Cue", "text": "but I think that by recognizing", "time": 781880}, {"__typename": "Cue", "text": "that the regulation of driverless cars\nis not only a technological problem", "time": 783440}, {"__typename": "Cue", "text": "but also a societal cooperation problem,", "time": 789600}, {"__typename": "Cue", "text": "I hope that we can at least begin\nto ask the right questions.", "time": 793800}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Thank you.", "time": 797200}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Applause)", "time": 798440}]}]}, "video": {"__typename": "Video", "id": "2824", "talkExtras": {"__typename": "TalkExtras", "footnotes": []}}}, "commentsEnabled": false, "commentsLoggedInOnly": false}, "language": "en", "messages": {}, "responseCode": 200, "__N_SSP": true}