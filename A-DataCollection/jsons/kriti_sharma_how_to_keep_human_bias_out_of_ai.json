{"pageProps": {"talksPageBanner": {"banner": {"title": "TP TEDLive 9/28/23", "slug": "tp-tedlive-9-28-23", "bannerLocation": "talks", "displayToExistingMembers": true, "mainContentHeadline": "Experience the TEDWomen conference from anywhere", "mainContent": "Don't miss out! Be one of the first to see our powerful new talks. ", "buttonLabel": "Count me in", "buttonLink": "https://membership.ted.com/tedwomen-live?utm_medium=website&utm_source=talkpage&utm_campaign=membership-ted&utm_content=09282023-tedlivetp", "showButtonIcon": false, "backgroundColor": "#000000", "textColor": "#FFFFFF", "useBackgroundGradient": false, "imageMobileBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4gxlFyoebOJrZojA12T8oX", "type": "Asset", "createdAt": "2023-09-28T20:19:28.480Z", "updatedAt": "2023-09-28T20:19:28.480Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Portrait Talks (3)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4gxlFyoebOJrZojA12T8oX/bfca75421f299110dacc3d9ed806f94d/TED_Tech_Jun_12_Tablet_Portrait_Talks__3_.png", "details": {"size": 468918, "image": {"width": 1483, "height": 236}}, "fileName": "TED_Tech_Jun_12_Tablet_Portrait_Talks (3).png", "contentType": "image/png"}}}, "imageTabletBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "ObeWsCx1H7GEtlIkKtvyF", "type": "Asset", "createdAt": "2023-09-28T20:19:28.484Z", "updatedAt": "2023-09-28T20:19:28.484Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Tablet Landscape Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/ObeWsCx1H7GEtlIkKtvyF/c246b94cd6fadb4394e2b8d2a5c74f0f/TED_Tech_Jun_12_Tablet_Landscape_Talks__5_.png", "details": {"size": 519237, "image": {"width": 2038, "height": 320}}, "fileName": "TED_Tech_Jun_12_Tablet_Landscape_Talks (5).png", "contentType": "image/png"}}}, "imageDesktopBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4mF9JrHls8kG41J85Bg5ZW", "type": "Asset", "createdAt": "2023-09-28T20:19:28.486Z", "updatedAt": "2023-09-28T20:19:28.486Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Desktop Talks (5)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4mF9JrHls8kG41J85Bg5ZW/621f89a67d4cdc8bb0ddac22065eab6c/TED_Tech_Jun_12_Desktop_Talks__6_.png", "details": {"size": 515590, "image": {"width": 1203, "height": 328}}, "fileName": "TED_Tech_Jun_12_Desktop_Talks (6).png", "contentType": "image/png"}}}, "imageXLBreakpoint": {"metadata": {"tags": []}, "sys": {"space": {"sys": {"type": "Link", "linkType": "Space", "id": "ab732rbh901q"}}, "id": "4OOqb4MoXPyzcuWcMJdjVn", "type": "Asset", "createdAt": "2023-09-28T20:21:34.825Z", "updatedAt": "2023-09-28T20:21:34.825Z", "environment": {"sys": {"id": "master", "type": "Link", "linkType": "Environment"}}, "revision": 1, "locale": "en-US"}, "fields": {"title": "TED Tech Jun 12 Mobile Talks (7)", "description": "", "file": {"url": "//images.ctfassets.net/ab732rbh901q/4OOqb4MoXPyzcuWcMJdjVn/cfa6e256f33e3ed7bd208289f391d750/TED_Tech_Jun_12_Mobile_Talks__7_.png", "details": {"size": 451422, "image": {"width": 1121, "height": 265}}, "fileName": "TED_Tech_Jun_12_Mobile_Talks (7).png", "contentType": "image/png"}}}}, "status": "published"}, "preview": false, "shortenedUrl": "https://go.ted.com/6WPv", "action": null, "videoData": {"__typename": "Video", "id": "36479", "slug": "kriti_sharma_how_to_keep_human_bias_out_of_ai", "title": "How to keep human bias out of AI", "socialTitle": "How to keep human bias out of AI", "presenterDisplayName": "Kriti Sharma", "internalLanguageCode": "en", "commentsEnabled": false, "commentsLoggedInOnly": false, "recordedOn": "2018-03-03", "curatorApproved": true, "viewedCount": 2334844, "duration": 720, "publishedAt": "2019-03-15T15:22:20Z", "topics": {"__typename": "TopicConnection", "nodes": [{"__typename": "Topic", "id": "10", "name": "technology", "slug": "technology"}, {"__typename": "Topic", "id": "36", "name": "computers", "slug": "computers"}, {"__typename": "Topic", "id": "42", "name": "software", "slug": "software"}, {"__typename": "Topic", "id": "55", "name": "social change", "slug": "social+change"}, {"__typename": "Topic", "id": "92", "name": "activism", "slug": "activism"}, {"__typename": "Topic", "id": "98", "name": "product design", "slug": "product+design"}, {"__typename": "Topic", "id": "184", "name": "AI", "slug": "ai"}, {"__typename": "Topic", "id": "273", "name": "TEDx", "slug": "tedx"}, {"__typename": "Topic", "id": "335", "name": "algorithm", "slug": "algorithm"}, {"__typename": "Topic", "id": "423", "name": "code", "slug": "code"}, {"__typename": "Topic", "id": "478", "name": "machine learning", "slug": "machine+learning"}, {"__typename": "Topic", "id": "1181", "name": "diversity", "slug": "diversity"}, {"__typename": "Topic", "id": "5790", "name": "equality", "slug": "equality"}]}, "talkExtras": {"__typename": "TalkExtras", "recommendations": [], "takeAction": [{"__typename": "TakeActionModule", "blurb": "**Learn more** and collaborate on applying AI for good.", "endAt": null, "eyebrow": null, "linkUrl": "https://www.aiforgood.co.uk/", "published": true, "startAt": null, "status": "APPROVED", "verb": "participate", "visibleUrl": "aiforgood.co.uk"}], "learnModules": []}, "primaryImageSet": [{"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/441028fd-5018-4a46-9ac7-2389b7e2c3d5/KritiSharma_2018X-embed.jpg", "aspectRatioName": "16x9"}, {"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/46fa4af4-716a-4b5c-9830-1b0f700c868b/KritiSharma_2018X-stageshot.jpg", "aspectRatioName": "4x3"}, {"__typename": "PhotoSize", "url": "https://talkstar-photos.s3.amazonaws.com/uploads/1820532e-b275-474a-a35f-625b078f7a55/KritiSharma_2018X-1350x675.jpg", "aspectRatioName": "2x1"}], "relatedVideos": [{"__typename": "Video", "slug": "joy_buolamwini_how_i_m_fighting_bias_in_algorithms", "id": "2705"}, {"__typename": "Video", "slug": "kai_fu_lee_how_ai_can_save_our_humanity", "id": "20368"}, {"__typename": "Video", "slug": "zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads", "id": "3595"}, {"__typename": "Video", "slug": "max_tegmark_how_to_get_empowered_not_overpowered_by_ai", "id": "17851"}, {"__typename": "Video", "slug": "kevin_kelly_how_ai_can_bring_on_a_second_industrial_revolution", "id": "2645"}, {"__typename": "Video", "slug": "sam_harris_can_we_build_ai_without_losing_control_over_it", "id": "2592"}], "customContentDetails": {"__typename": "CustomContentDetails", "partnerName": null}, "speakers": {"__typename": "AcmeSpeakerConnection", "nodes": [{"__typename": "AcmeSpeaker", "photoUrl": "https://pe.tedcdn.com/images/ted/e707751e6befe482cf02e7a49a678e0077baaffb_254x191.jpg", "firstname": "Kriti", "middlename": "", "lastname": "Sharma", "description": "AI technologist", "isLive": true, "title": "", "whatOthersSay": "", "whoTheyAre": "Kriti Sharma creates AI technology to help address some of the toughest social challenges of our time -- from domestic violence to sexual health and inequality.", "whyListen": "<p>Kriti Sharma is the Founder of AI for Good, an organization focused on building scalable technology solutions for social good. In 2018, she also launched rAInbow, a digital companion for women facing domestic violence in South Africa. This service reached nearly 200,000 conversations within the first 100 days, breaking down the stigma of gender-based violence. In 2019, she collaborated with the Population Foundation of India to launch Dr. Sneha, an AI-powered digital character to engage with young people about sexual health, an issue that is still considered a taboo in India.&nbsp;</p><p>Sharma was recently named in the <em>Forbes</em>&nbsp;&quot;30 Under 30&quot; list for advancements in AI. She was appointed a United Nations Young Leader in 2018 and is an advisor to both the United Nations Technology Innovation Labs and to the UK Government&rsquo;s Centre for Data Ethics and Innovation.&nbsp;</p>", "slug": "kriti_sharma"}]}, "description": "AI algorithms make important decisions about you all the time -- like how much you should pay for car insurance or whether or not you get that job interview. But what happens when these machines are built with human bias coded into their systems? Technologist Kriti Sharma explores how the lack of diversity in tech is creeping into our AI, offering three ways we can start making more ethical algorithms.", "socialDescription": "AI algorithms make important decisions about you all the time -- like how much you should pay for car insurance or whether or not you get that job interview. But what happens when these machines are built with human bias coded into their systems? Technologist Kriti Sharma explores how the lack of diversity in tech is creeping into our AI, offering three ways we can start making more ethical algorithms.", "partnerName": null, "playerData": "{\"id\":\"36479\",\"mediaIdentifier\":\"consus-pm428-im2346\",\"mediaProjectVersionIdentifier\":\"consus-pm428-im2346\",\"duration\":730,\"languages\":[{\"languageName\":\"English\",\"endonym\":\"English\",\"languageCode\":\"en\",\"ianaCode\":\"en\",\"isRtl\":false},{\"languageName\":\"Korean\",\"endonym\":\"\ud55c\uad6d\uc5b4\",\"languageCode\":\"ko\",\"ianaCode\":\"ko\",\"isRtl\":false},{\"languageName\":\"Chinese, Traditional\",\"endonym\":\"\u4e2d\u6587 (\u7e41\u9ad4)\",\"languageCode\":\"zh-tw\",\"ianaCode\":\"zh-Hant\",\"isRtl\":false},{\"languageName\":\"Portuguese, Brazilian\",\"endonym\":\"Portugu\u00eas brasileiro\",\"languageCode\":\"pt-br\",\"ianaCode\":\"pt-BR\",\"isRtl\":false},{\"languageName\":\"Persian\",\"endonym\":\"\u0641\u0627\u0631\u0633\u0649\",\"languageCode\":\"fa\",\"ianaCode\":\"fa\",\"isRtl\":true},{\"languageName\":\"Romanian\",\"endonym\":\"Rom\u00e2n\u0103\",\"languageCode\":\"ro\",\"ianaCode\":\"ro\",\"isRtl\":false},{\"languageName\":\"Hungarian\",\"endonym\":\"Magyar\",\"languageCode\":\"hu\",\"ianaCode\":\"hu\",\"isRtl\":false},{\"languageName\":\"Spanish\",\"endonym\":\"Espa\u00f1ol\",\"languageCode\":\"es\",\"ianaCode\":\"es\",\"isRtl\":false},{\"languageName\":\"Italian\",\"endonym\":\"Italiano\",\"languageCode\":\"it\",\"ianaCode\":\"it\",\"isRtl\":false},{\"languageName\":\"Chinese, Simplified\",\"endonym\":\"\u4e2d\u6587 (\u7b80\u4f53)\",\"languageCode\":\"zh-cn\",\"ianaCode\":\"zh-Hans\",\"isRtl\":false},{\"languageName\":\"Portuguese\",\"endonym\":\"Portugu\u00eas de Portugal\",\"languageCode\":\"pt\",\"ianaCode\":\"pt\",\"isRtl\":false},{\"languageName\":\"Hebrew\",\"endonym\":\"\u05e2\u05d1\u05e8\u05d9\u05ea\",\"languageCode\":\"he\",\"ianaCode\":\"he\",\"isRtl\":true},{\"languageName\":\"French\",\"endonym\":\"Fran\u00e7ais\",\"languageCode\":\"fr\",\"ianaCode\":\"fr\",\"isRtl\":false},{\"languageName\":\"Turkish\",\"endonym\":\"T\u00fcrk\u00e7e\",\"languageCode\":\"tr\",\"ianaCode\":\"tr\",\"isRtl\":false},{\"languageName\":\"Arabic\",\"endonym\":\"\u0627\u0644\u0639\u0631\u0628\u064a\u0629\",\"languageCode\":\"ar\",\"ianaCode\":\"ar\",\"isRtl\":true},{\"languageName\":\"Russian\",\"endonym\":\"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\",\"languageCode\":\"ru\",\"ianaCode\":\"ru\",\"isRtl\":false},{\"languageName\":\"German\",\"endonym\":\"Deutsch\",\"languageCode\":\"de\",\"ianaCode\":\"de\",\"isRtl\":false},{\"languageName\":\"Vietnamese\",\"endonym\":\"Ti\u1ebfng Vi\u1ec7t\",\"languageCode\":\"vi\",\"ianaCode\":\"vi\",\"isRtl\":false}],\"nativeLanguage\":\"en\",\"isSubtitleRequired\":false,\"resources\":{\"h264\":[{\"bitrate\":1200,\"file\":\"https://py.tedcdn.com/consus/projects/00/04/35/005/products/2018x-kriti-sharma-005-fallback-8672bc552c59c7fd4bd2c468386f8311-1200k.mp4\"}],\"hls\":{\"adUrl\":\"https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTEDxWarwick%26id%3D36479%26tag%3DAI%2Cmachine%2Blearning%2Ctechnology%2Cdiversity%2Calgorithm%2Csoftware%2Csocial%2Bchange%2CTEDx%2Ccomputers%2Cproduct%2Bdesign%2Ccode%2Cactivism%2Cequality%26talk%3Dkriti_sharma_how_to_keep_human_bias_out_of_ai%26year%3D2018&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D\",\"maiTargeting\":{\"id\":\"36479\",\"talk\":\"kriti_sharma_how_to_keep_human_bias_out_of_ai\",\"tag\":\"AI,machine learning,technology,diversity,algorithm,software,social change,TEDx,computers,product design,code,activism,equality\",\"year\":\"2018\",\"event\":\"TEDxWarwick\"},\"stream\":\"https://hls.ted.com/project_masters/428/manifest.m3u8?intro_master_id=2346\",\"metadata\":\"https://hls.ted.com/project_masters/428/metadata.json?intro_master_id=2346\"}},\"targeting\":{\"id\":\"36479\",\"talk\":\"kriti_sharma_how_to_keep_human_bias_out_of_ai\",\"tag\":\"AI,machine learning,technology,diversity,algorithm,software,social change,TEDx,computers,product design,code,activism,equality\",\"year\":\"2018\",\"event\":\"TEDxWarwick\"},\"canonical\":\"https://www.ted.com/talks/kriti_sharma_how_to_keep_human_bias_out_of_ai\",\"name\":\"Kriti Sharma: How to keep human bias out of AI\",\"title\":\"How to keep human bias out of AI\",\"speaker\":\"Kriti Sharma\",\"thumb\":\"https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/441028fd-5018-4a46-9ac7-2389b7e2c3d5/KritiSharma_2018X-embed.jpg?quality=89&w=600\",\"slug\":\"kriti_sharma_how_to_keep_human_bias_out_of_ai\",\"event\":\"TEDxWarwick\",\"published\":1552663340,\"external\":{\"service\":\"YouTube\",\"code\":\"BRRNeBKwvNM\",\"duration\":731.0,\"start_time\":0.0}}", "videoContext": "TEDxWarwick", "audioInternalLanguageCode": "en", "language": "en", "hasTranslations": true, "featured": true, "type": {"__typename": "TypeOfVideo", "id": "2", "name": "TEDx Talk"}}, "transcriptData": {"translation": {"__typename": "Translation", "id": "153843", "language": {"__typename": "Language", "id": "35", "endonym": "English", "englishName": "English", "internalLanguageCode": "en", "rtl": false}, "reviewer": {"__typename": "User", "id": "230475", "uri": "/profiles/230587", "avatar": {"__typename": "UserAvatar", "url": "https://s3.amazonaws.com/ted.conferences.profiles/00/00/00/8b/38/35640.jpg", "generatedUrl": "https://avatars.ted.com/v1/avatar/1345470282.svg"}, "name": {"__typename": "UserName", "full": "Joanna Pietrulewicz"}}, "translator": {"__typename": "User", "id": "377201", "uri": "/profiles/377323", "avatar": {"__typename": "UserAvatar", "url": "https://s3.amazonaws.com/ted.conferences.profiles/00/00/13/88/56/1280086.jpeg", "generatedUrl": "https://avatars.ted.com/v1/avatar/1345425649.svg"}, "name": {"__typename": "UserName", "full": "Ivana Korom"}}, "paragraphs": [{"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "How many decisions\nhave been made about you today,", "time": 875}, {"__typename": "Cue", "text": "or this week or this year,", "time": 4667}, {"__typename": "Cue", "text": "by artificial intelligence?", "time": 7292}, {"__typename": "Cue", "text": "I build AI for a living", "time": 10958}, {"__typename": "Cue", "text": "so, full disclosure, I'm kind of a nerd.", "time": 12667}, {"__typename": "Cue", "text": "And because I'm kind of a nerd,", "time": 15708}, {"__typename": "Cue", "text": "wherever some new news story comes out", "time": 18125}, {"__typename": "Cue", "text": "about artificial intelligence\nstealing all our jobs,", "time": 20500}, {"__typename": "Cue", "text": "or robots getting citizenship\nof an actual country,", "time": 23958}, {"__typename": "Cue", "text": "I'm the person my friends\nand followers message", "time": 28167}, {"__typename": "Cue", "text": "freaking out about the future.", "time": 31333}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We see this everywhere.", "time": 33833}, {"__typename": "Cue", "text": "This media panic that\nour robot overlords are taking over.", "time": 35958}, {"__typename": "Cue", "text": "We could blame Hollywood for that.", "time": 40875}, {"__typename": "Cue", "text": "But in reality, that's not the problem\nwe should be focusing on.", "time": 44125}, {"__typename": "Cue", "text": "There is a more pressing danger,\na bigger risk with AI,", "time": 49250}, {"__typename": "Cue", "text": "that we need to fix first.", "time": 52917}, {"__typename": "Cue", "text": "So we are back to this question:", "time": 55417}, {"__typename": "Cue", "text": "How many decisions\nhave been made about you today by AI?", "time": 57750}, {"__typename": "Cue", "text": "And how many of these", "time": 63792}, {"__typename": "Cue", "text": "were based on your gender,\nyour race or your background?", "time": 65792}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Algorithms are being used all the time", "time": 72500}, {"__typename": "Cue", "text": "to make decisions about who we are\nand what we want.", "time": 75292}, {"__typename": "Cue", "text": "Some of the women in this room\nwill know what I'm talking about", "time": 80208}, {"__typename": "Cue", "text": "if you've been made to sit through\nthose pregnancy test adverts on YouTube", "time": 83875}, {"__typename": "Cue", "text": "like 1,000 times.", "time": 87667}, {"__typename": "Cue", "text": "Or you've scrolled past adverts\nof fertility clinics", "time": 89750}, {"__typename": "Cue", "text": "on your Facebook feed.", "time": 92625}, {"__typename": "Cue", "text": "Or in my case, Indian marriage bureaus.", "time": 95625}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 98042}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "But AI isn't just being used\nto make decisions", "time": 99333}, {"__typename": "Cue", "text": "about what products we want to buy", "time": 102333}, {"__typename": "Cue", "text": "or which show we want to binge watch next.", "time": 104958}, {"__typename": "Cue", "text": "I wonder how you'd feel about someone\nwho thought things like this:", "time": 109042}, {"__typename": "Cue", "text": "\"A black or Latino person", "time": 114250}, {"__typename": "Cue", "text": "is less likely than a white person\nto pay off their loan on time.\"", "time": 116208}, {"__typename": "Cue", "text": "\"A person called John\nmakes a better programmer", "time": 121542}, {"__typename": "Cue", "text": "than a person called Mary.\"", "time": 124375}, {"__typename": "Cue", "text": "\"A black man is more likely to be\na repeat offender than a white man.\"", "time": 127250}, {"__typename": "Cue", "text": "You're probably thinking,", "time": 134958}, {"__typename": "Cue", "text": "\"Wow, that sounds like a pretty sexist,\nracist person,\" right?", "time": 136250}, {"__typename": "Cue", "text": "These are some real decisions\nthat AI has made very recently,", "time": 141000}, {"__typename": "Cue", "text": "based on the biases\nit has learned from us,", "time": 145875}, {"__typename": "Cue", "text": "from the humans.", "time": 148833}, {"__typename": "Cue", "text": "AI is being used to help decide\nwhether or not you get that job interview;", "time": 151750}, {"__typename": "Cue", "text": "how much you pay for your car insurance;", "time": 156583}, {"__typename": "Cue", "text": "how good your credit score is;", "time": 159000}, {"__typename": "Cue", "text": "and even what rating you get\nin your annual performance review.", "time": 160917}, {"__typename": "Cue", "text": "But these decisions\nare all being filtered through", "time": 165083}, {"__typename": "Cue", "text": "its assumptions about our identity,\nour race, our gender, our age.", "time": 168250}, {"__typename": "Cue", "text": "How is that happening?", "time": 176250}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Now, imagine an AI is helping\na hiring manager", "time": 178542}, {"__typename": "Cue", "text": "find the next tech leader in the company.", "time": 182083}, {"__typename": "Cue", "text": "So far, the manager\nhas been hiring mostly men.", "time": 184958}, {"__typename": "Cue", "text": "So the AI learns men are more likely\nto be programmers than women.", "time": 188083}, {"__typename": "Cue", "text": "And it's a very short leap from there to:", "time": 193542}, {"__typename": "Cue", "text": "men make better programmers than women.", "time": 196458}, {"__typename": "Cue", "text": "We have reinforced\nour own bias into the AI.", "time": 199417}, {"__typename": "Cue", "text": "And now, it's screening out\nfemale candidates.", "time": 203167}, {"__typename": "Cue", "text": "Hang on, if a human\nhiring manager did that,", "time": 208917}, {"__typename": "Cue", "text": "we'd be outraged, we wouldn't allow it.", "time": 211958}, {"__typename": "Cue", "text": "This kind of gender\ndiscrimination is not OK.", "time": 214333}, {"__typename": "Cue", "text": "And yet somehow,\nAI has become above the law,", "time": 217833}, {"__typename": "Cue", "text": "because a machine made the decision.", "time": 222375}, {"__typename": "Cue", "text": "That's not it.", "time": 225833}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "We are also reinforcing our bias\nin how we interact with AI.", "time": 227375}, {"__typename": "Cue", "text": "How often do you use a voice assistant\nlike Siri, Alexa or even Cortana?", "time": 232917}, {"__typename": "Cue", "text": "They all have two things in common:", "time": 238917}, {"__typename": "Cue", "text": "one, they can never get my name right,", "time": 241500}, {"__typename": "Cue", "text": "and second, they are all female.", "time": 244625}, {"__typename": "Cue", "text": "They are designed to be\nour obedient servants,", "time": 248417}, {"__typename": "Cue", "text": "turning your lights on and off,\nordering your shopping.", "time": 251208}, {"__typename": "Cue", "text": "You get male AIs too,\nbut they tend to be more high-powered,", "time": 255125}, {"__typename": "Cue", "text": "like IBM Watson,\nmaking business decisions,", "time": 258458}, {"__typename": "Cue", "text": "Salesforce Einstein\nor ROSS, the robot lawyer.", "time": 261541}, {"__typename": "Cue", "text": "So poor robots, even they suffer\nfrom sexism in the workplace.", "time": 266208}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 270292}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Think about how these two things combine", "time": 272542}, {"__typename": "Cue", "text": "and affect a kid growing up\nin today's world around AI.", "time": 275417}, {"__typename": "Cue", "text": "So they're doing some research\nfor a school project", "time": 280750}, {"__typename": "Cue", "text": "and they Google images of CEO.", "time": 283708}, {"__typename": "Cue", "text": "The algorithm shows them\nresults of mostly men.", "time": 286750}, {"__typename": "Cue", "text": "And now, they Google personal assistant.", "time": 289667}, {"__typename": "Cue", "text": "As you can guess,\nit shows them mostly females.", "time": 292250}, {"__typename": "Cue", "text": "And then they want to put on some music,\nand maybe order some food,", "time": 295708}, {"__typename": "Cue", "text": "and now, they are barking orders\nat an obedient female voice assistant.", "time": 299333}, {"__typename": "Cue", "text": "Some of our brightest minds\nare creating this technology today.", "time": 307542}, {"__typename": "Cue", "text": "Technology that they could have created\nin any way they wanted.", "time": 312875}, {"__typename": "Cue", "text": "And yet, they have chosen to create it\nin the style of 1950s \"Mad Man\" secretary.", "time": 317083}, {"__typename": "Cue", "text": "Yay!", "time": 322792}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "But OK, don't worry,", "time": 324958}, {"__typename": "Cue", "text": "this is not going to end\nwith me telling you", "time": 326292}, {"__typename": "Cue", "text": "that we are all heading towards\nsexist, racist machines running the world.", "time": 328375}, {"__typename": "Cue", "text": "The good news about AI\nis that it is entirely within our control.", "time": 332792}, {"__typename": "Cue", "text": "We get to teach the right values,\nthe right ethics to AI.", "time": 339333}, {"__typename": "Cue", "text": "So there are three things we can do.", "time": 344167}, {"__typename": "Cue", "text": "One, we can be aware of our own biases", "time": 346375}, {"__typename": "Cue", "text": "and the bias in machines around us.", "time": 349750}, {"__typename": "Cue", "text": "Two, we can make sure that diverse teams\nare building this technology.", "time": 352500}, {"__typename": "Cue", "text": "And three, we have to give it\ndiverse experiences to learn from.", "time": 357042}, {"__typename": "Cue", "text": "I can talk about the first two\nfrom personal experience.", "time": 362875}, {"__typename": "Cue", "text": "When you work in technology", "time": 366208}, {"__typename": "Cue", "text": "and you don't look like\na Mark Zuckerberg or Elon Musk,", "time": 367667}, {"__typename": "Cue", "text": "your life is a little bit difficult,\nyour ability gets questioned.", "time": 371083}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Here's just one example.", "time": 375875}, {"__typename": "Cue", "text": "Like most developers,\nI often join online tech forums", "time": 377292}, {"__typename": "Cue", "text": "and share my knowledge to help others.", "time": 381042}, {"__typename": "Cue", "text": "And I've found,", "time": 384292}, {"__typename": "Cue", "text": "when I log on as myself,\nwith my own photo, my own name,", "time": 385625}, {"__typename": "Cue", "text": "I tend to get questions\nor comments like this:", "time": 389625}, {"__typename": "Cue", "text": "\"What makes you think\nyou're qualified to talk about AI?\"", "time": 394250}, {"__typename": "Cue", "text": "\"What makes you think\nyou know about machine learning?\"", "time": 398458}, {"__typename": "Cue", "text": "So, as you do, I made a new profile,", "time": 401958}, {"__typename": "Cue", "text": "and this time, instead of my own picture,\nI chose a cat with a jet pack on it.", "time": 405417}, {"__typename": "Cue", "text": "And I chose a name\nthat did not reveal my gender.", "time": 410292}, {"__typename": "Cue", "text": "You can probably guess\nwhere this is going, right?", "time": 413917}, {"__typename": "Cue", "text": "So, this time, I didn't get any of those\npatronizing comments about my ability", "time": 416667}, {"__typename": "Cue", "text": "and I was able to actually\nget some work done.", "time": 423083}, {"__typename": "Cue", "text": "And it sucks, guys.", "time": 427500}, {"__typename": "Cue", "text": "I've been building robots since I was 15,", "time": 429375}, {"__typename": "Cue", "text": "I have a few degrees in computer science,", "time": 431875}, {"__typename": "Cue", "text": "and yet, I had to hide my gender", "time": 434167}, {"__typename": "Cue", "text": "in order for my work\nto be taken seriously.", "time": 436625}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So, what's going on here?", "time": 439875}, {"__typename": "Cue", "text": "Are men just better\nat technology than women?", "time": 441792}, {"__typename": "Cue", "text": "Another study found", "time": 445917}, {"__typename": "Cue", "text": "that when women coders on one platform\nhid their gender, like myself,", "time": 447500}, {"__typename": "Cue", "text": "their code was accepted\nfour percent more than men.", "time": 452458}, {"__typename": "Cue", "text": "So this is not about the talent.", "time": 456542}, {"__typename": "Cue", "text": "This is about an elitism in AI", "time": 459958}, {"__typename": "Cue", "text": "that says a programmer\nneeds to look like a certain person.", "time": 462875}, {"__typename": "Cue", "text": "What we really need to do\nto make AI better", "time": 467375}, {"__typename": "Cue", "text": "is bring people\nfrom all kinds of backgrounds.", "time": 470500}, {"__typename": "Cue", "text": "We need people who can\nwrite and tell stories", "time": 474542}, {"__typename": "Cue", "text": "to help us create personalities of AI.", "time": 477125}, {"__typename": "Cue", "text": "We need people who can solve problems.", "time": 480208}, {"__typename": "Cue", "text": "We need people\nwho face different challenges", "time": 483125}, {"__typename": "Cue", "text": "and we need people who can tell us\nwhat are the real issues that need fixing", "time": 486917}, {"__typename": "Cue", "text": "and help us find ways\nthat technology can actually fix it.", "time": 492292}, {"__typename": "Cue", "text": "Because, when people\nfrom diverse backgrounds come together,", "time": 497833}, {"__typename": "Cue", "text": "when we build things in the right way,", "time": 501583}, {"__typename": "Cue", "text": "the possibilities are limitless.", "time": 503750}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "And that's what I want to end\nby talking to you about.", "time": 506750}, {"__typename": "Cue", "text": "Less racist robots, less machines\nthat are going to take our jobs --", "time": 510083}, {"__typename": "Cue", "text": "and more about what technology\ncan actually achieve.", "time": 514332}, {"__typename": "Cue", "text": "So, yes, some of the energy\nin the world of AI,", "time": 518292}, {"__typename": "Cue", "text": "in the world of technology", "time": 521750}, {"__typename": "Cue", "text": "is going to be about\nwhat ads you see on your stream.", "time": 523167}, {"__typename": "Cue", "text": "But a lot of it is going towards\nmaking the world so much better.", "time": 527458}, {"__typename": "Cue", "text": "Think about a pregnant woman\nin the Democratic Republic of Congo,", "time": 533500}, {"__typename": "Cue", "text": "who has to walk 17 hours\nto her nearest rural prenatal clinic", "time": 537292}, {"__typename": "Cue", "text": "to get a checkup.", "time": 541500}, {"__typename": "Cue", "text": "What if she could get diagnosis\non her phone, instead?", "time": 543375}, {"__typename": "Cue", "text": "Or think about what AI could do", "time": 547750}, {"__typename": "Cue", "text": "for those one in three women\nin South Africa", "time": 549583}, {"__typename": "Cue", "text": "who face domestic violence.", "time": 552333}, {"__typename": "Cue", "text": "If it wasn't safe to talk out loud,", "time": 555083}, {"__typename": "Cue", "text": "they could get an AI service\nto raise alarm,", "time": 557833}, {"__typename": "Cue", "text": "get financial and legal advice.", "time": 560333}, {"__typename": "Cue", "text": "These are all real examples of projects\nthat people, including myself,", "time": 563958}, {"__typename": "Cue", "text": "are working on right now, using AI.", "time": 569000}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "So, I'm sure in the next couple of days\nthere will be yet another news story", "time": 573542}, {"__typename": "Cue", "text": "about the existential risk,", "time": 577167}, {"__typename": "Cue", "text": "robots taking over\nand coming for your jobs.", "time": 579875}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Laughter)", "time": 582333}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "And when something like that happens,", "time": 583375}, {"__typename": "Cue", "text": "I know I'll get the same messages\nworrying about the future.", "time": 585708}, {"__typename": "Cue", "text": "But I feel incredibly positive\nabout this technology.", "time": 589333}, {"__typename": "Cue", "text": "This is our chance to remake the world\ninto a much more equal place.", "time": 595458}, {"__typename": "Cue", "text": "But to do that, we need to build it\nthe right way from the get go.", "time": 602458}, {"__typename": "Cue", "text": "We need people of different genders,\nraces, sexualities and backgrounds.", "time": 607667}, {"__typename": "Cue", "text": "We need women to be the makers", "time": 614458}, {"__typename": "Cue", "text": "and not just the machines\nwho do the makers' bidding.", "time": 616958}, {"__typename": "Cue", "text": "We need to think very carefully\nwhat we teach machines,", "time": 621875}, {"__typename": "Cue", "text": "what data we give them,", "time": 625667}, {"__typename": "Cue", "text": "so they don't just repeat\nour own past mistakes.", "time": 627333}, {"__typename": "Cue", "text": "So I hope I leave you\nthinking about two things.", "time": 632125}, {"__typename": "Cue", "text": "First, I hope you leave\nthinking about bias today.", "time": 636542}, {"__typename": "Cue", "text": "And that the next time\nyou scroll past an advert", "time": 641125}, {"__typename": "Cue", "text": "that assumes you are interested\nin fertility clinics", "time": 644333}, {"__typename": "Cue", "text": "or online betting websites,", "time": 647167}, {"__typename": "Cue", "text": "that you think and remember", "time": 650042}, {"__typename": "Cue", "text": "that the same technology is assuming\nthat a black man will reoffend.", "time": 652083}, {"__typename": "Cue", "text": "Or that a woman is more likely\nto be a personal assistant than a CEO.", "time": 657833}, {"__typename": "Cue", "text": "And I hope that reminds you\nthat we need to do something about it.", "time": 662958}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "And second,", "time": 668917}, {"__typename": "Cue", "text": "I hope you think about the fact", "time": 670792}, {"__typename": "Cue", "text": "that you don't need to look a certain way", "time": 672708}, {"__typename": "Cue", "text": "or have a certain background\nin engineering or technology", "time": 674708}, {"__typename": "Cue", "text": "to create AI,", "time": 678583}, {"__typename": "Cue", "text": "which is going to be\na phenomenal force for our future.", "time": 679875}, {"__typename": "Cue", "text": "You don't need to look\nlike a Mark Zuckerberg,", "time": 684166}, {"__typename": "Cue", "text": "you can look like me.", "time": 686333}, {"__typename": "Cue", "text": "And it is up to all of us in this room", "time": 689250}, {"__typename": "Cue", "text": "to convince the governments\nand the corporations", "time": 692167}, {"__typename": "Cue", "text": "to build AI technology for everyone,", "time": 694917}, {"__typename": "Cue", "text": "including the edge cases.", "time": 697833}, {"__typename": "Cue", "text": "And for us all to get education", "time": 700250}, {"__typename": "Cue", "text": "about this phenomenal\ntechnology in the future.", "time": 702333}, {"__typename": "Cue", "text": "Because if we do that,", "time": 706167}, {"__typename": "Cue", "text": "then we've only just scratched the surface\nof what we can achieve with AI.", "time": 708208}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "Thank you.", "time": 713125}]}, {"__typename": "Paragraph", "cues": [{"__typename": "Cue", "text": "(Applause)", "time": 714417}]}]}, "video": {"__typename": "Video", "id": "36479", "talkExtras": {"__typename": "TalkExtras", "footnotes": [{"__typename": "Footnote", "author": null, "annotation": "> \"This kind of gender discrimination is not OK. And yet somehow, AI has become above the law, because a machine made the decision.\"\r\n\r\nAI algorithms are helping make critical decisions in areas such as crime and policing, credit and lending, recruitment and health care. This is often powered by a technique called deep learning, which makes it difficult to build [\"explainability\"](https://www.economist.com/science-and-technology/2018/02/15/for-artificial-intelligence-to-thrive-it-must-explain-itself) into the algorithms, thereby reducing trust.\r\n\r\nThis lack of transparency into explaining how algorithmic decisions are made is raising questions and calls for regulation of AI technology. However, the technology community, policy makers and members of the civil society are divided on how to move forward -- between issuing guidelines on ethical development of AI vs. stronger regulatory and legal measures. The UK government has established the [Centre for Data Ethics and Innovation](https://www.gov.uk/government/groups/centre-for-data-ethics-and-innovation-cdei); the European Commission's High-Level Expert Group on Artificial Intelligence has issued a set of [guidelines](https://ec.europa.eu/digital-single-market/en/news/have-your-say-european-expert-group-seeks-feedback-draft-ethics-guidelines-trustworthy); and President Trump's White House has taken a different [approach](https://www.whitehouse.gov/wp-content/uploads/2018/05/Summary-Report-of-White-House-AI-Summit.pdf).", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "03:45", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"... they're doing some research for a school project and they Google images of CEO. The algorithm shows them results of mostly men.\"\r\n\r\nAI algorithms learn from the data that is used to train the machine learning model. If the underlying data is biased, like in the case of images of CEOs, the AI-powered algorithms are more likely to produce biased results. This [University of Washington study](https://www.washington.edu/news/2015/04/09/whos-a-ceo-google-image-results-can-shift-gender-biases/) found that women were significantly underrepresented in Google image searches results for a few jobs, including CEO. Another [study from MIT and Stanford University](http://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212) found that the error rate for facial recognition systems is much higher for darker skinned women (34.7 percent) than lighter skinned men (0.8 percent).", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "04:52", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"Another study found that when women coders on one platform hid their gender, like myself, their code was accepted four percent more than men.\"\r\n\r\nBias against women in the technology workplace is not an uncommon or unknown issue. However, it is interesting that these patterns also exist in open-source technology projects. As reported in [this study](https://peerj.com/articles/cs-111/) by Terrell J., et al., hiding gender identity revealed different acceptance rates for open-source pull requests.", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "07:37", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"... think about what AI could do for those one in three women in South Africa who face domestic violence.\"\r\n\r\nCorrection: Domestic violence can take many forms: physical, psychological, sexual, verbal, financial and even digital abuse. The incidents are often underreported due to cultural stigma and taboo around this issue. Worldwide, [almost one-third (30 percent) of all women](https://www.who.int/reproductivehealth/publications/violence/9789241564625/en/) who have been in a relationship have experienced physical and/or sexual violence by their intimate partner. In South Africa, it is estimated that [21 percent of women age 18 and older](http://www.statssa.gov.za/publications/Report%2003-00-09/Report%2003-00-092016.pdf, experienced physical violence by a partner, and 6 percent experienced sexual violence by a partner. Just under [50 percent of women in Gauteng, South Africa](http://genderlinks.org.za/programme-web-menu/publications/the-war-at-home-gbv-indicators-project-2011-08-16/) report having ever experienced emotional or economic abuse at the hands of their intimate partners in their lifetime. There is an urgent need to act on this topic, to predict and prevent instances of abuse, and to do it at scale.", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "09:19", "title": null, "category": "note"}, {"__typename": "Footnote", "author": null, "annotation": "> \"If it wasn't safe to talk out loud, they could get an AI service to raise alarm, get financial and legal advice.\"\r\n\r\n[rAInbow](https://www.hirainbow.org/) is one such example of using AI technology to tackle domestic violence. Launched in November 2018, rAInbow is an AI-powered digital companion for women at risk of domestic violence. It is designed to be unbiased, nonjudgmental and available 24/7 to give victims access to the resources and services they need, without having to deal with victim blaming or social taboo. Within the first 100 days of launch, rAInbow had nearly 200,000 conversations with women at risk of abuse in South Africa alone.", "date": null, "linkUrl": null, "source": null, "text": null, "timecode": "09:26", "title": null, "category": "note"}]}}}, "commentsEnabled": false, "commentsLoggedInOnly": false}, "language": "en", "messages": {}, "responseCode": 200, "__N_SSP": true}